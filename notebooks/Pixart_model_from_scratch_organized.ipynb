{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "from diffusers import AutoencoderKL, Transformer2DModel, PixArtAlphaPipeline, DPMSolverMultistepScheduler\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionObjectRelation/PixArt-alpha\")\n",
    "from diffusion import IDDPM\n",
    "from diffusion.data.builder import build_dataset, build_dataloader, set_data_root\n",
    "from diffusion.model.builder import build_model\n",
    "from diffusion.utils.misc import set_random_seed, read_config, init_random_seed, DebugUnderflowOverflow\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionObjectRelation/utils\")\n",
    "from pixart_utils import state_dict_convert\n",
    "from image_utils import pil_images_to_grid\n",
    "from pixart_utils import state_dict_convert\n",
    "from pixart_sampling_utils import PixArtAlphaPipeline_custom, visualize_prompts_with_traj\n",
    "from pixart_utils import construct_diffuser_transformer_from_config, construct_diffuser_pipeline_from_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 23:46:23,379 - PixArt - WARNING - lewei scale: (1.0,), base size: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f40b90a5064c0e85296fd46f1c7405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "savedir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/PixArt/results/objrel_rndembdposemb_DiT_B_pilot\"\n",
    "\n",
    "config = read_config(join(savedir, 'config.py'))\n",
    "\n",
    "weight_dtype = torch.float32\n",
    "if config.mixed_precision == \"fp16\": # accelerator.\n",
    "    weight_dtype = torch.float16\n",
    "elif config.mixed_precision == \"bf16\": # accelerator.\n",
    "    weight_dtype = torch.bfloat16\n",
    "    \n",
    "image_size = config.image_size  # @param [256, 512, 1024]\n",
    "latent_size = int(image_size) // 8\n",
    "pred_sigma = getattr(config, 'pred_sigma', True)\n",
    "learn_sigma = getattr(config, 'learn_sigma', True) and pred_sigma\n",
    "model_kwargs={\"window_block_indexes\": config.window_block_indexes, \"window_size\": config.window_size,\n",
    "                \"use_rel_pos\": config.use_rel_pos, \"lewei_scale\": config.lewei_scale, 'config':config,\n",
    "                'model_max_length': config.model_max_length}\n",
    "# train_diffusion = IDDPM(str(config.train_sampling_steps), learn_sigma=learn_sigma, pred_sigma=pred_sigma, snr=config.snr_loss)\n",
    "model = build_model(config.model,\n",
    "                config.grad_checkpointing,\n",
    "                config.get('fp32_attention', False),\n",
    "                input_size=latent_size,\n",
    "                learn_sigma=learn_sigma,\n",
    "                pred_sigma=pred_sigma,\n",
    "                **model_kwargs).train()\n",
    "\n",
    "transformer = Transformer2DModel(\n",
    "        sample_size=image_size // 8,\n",
    "        num_layers=len(model.blocks),\n",
    "        attention_head_dim=model.blocks[0].hidden_size // model.num_heads,\n",
    "        in_channels=model.in_channels,\n",
    "        out_channels=model.out_channels,\n",
    "        patch_size=model.patch_size,\n",
    "        attention_bias=True,\n",
    "        num_attention_heads=model.num_heads,\n",
    "        cross_attention_dim=model.blocks[0].hidden_size,\n",
    "        activation_fn=\"gelu-approximate\",\n",
    "        num_embeds_ada_norm=1000,\n",
    "        norm_type=\"ada_norm_single\",\n",
    "        norm_elementwise_affine=False,\n",
    "        norm_eps=1e-6,\n",
    "        caption_channels=4096,\n",
    ")\n",
    "# state_dict = state_dict_convert(all_state_dict.pop(\"state_dict\"))\n",
    "transformer.load_state_dict(state_dict_convert(model.state_dict()))\n",
    "pipeline = PixArtAlphaPipeline_custom.from_pretrained(\n",
    "    \"PixArt-alpha/PixArt-XL-2-512x512\",\n",
    "    transformer=transformer,\n",
    "    tokenizer=None,\n",
    "    text_encoder=None,\n",
    "    torch_dtype=weight_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckptdir = join(savedir, \"checkpoints\")\n",
    "ckpt = torch.load(join(ckptdir, \"epoch_4000_step_160000.pth\"))\n",
    "pipeline.transformer.load_state_dict(state_dict_convert(ckpt['state_dict_ema']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PixArt(\n",
       "  (x_embedder): PatchEmbed(\n",
       "    (proj): Conv2d(4, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (t_block): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=768, out_features=4608, bias=True)\n",
       "  )\n",
       "  (y_embedder): CaptionEmbedder(\n",
       "    (y_proj): Mlp(\n",
       "      (fc1): Linear(in_features=4096, out_features=768, bias=True)\n",
       "      (act): GELU(approximate='tanh')\n",
       "      (drop1): Dropout(p=0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x PixArtBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): WindowAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (cross_attn): MultiHeadCrossAttention(\n",
       "        (q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (kv_linear): Linear(in_features=768, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='tanh')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "    )\n",
       "  )\n",
       "  (final_layer): T2IFinalLayer(\n",
       "    (norm_final): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=768, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PixArt model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Embedding\n",
    "\n",
    "class PatchEmbeddingScratch(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, patch_size=2):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "                              kernel_size=(patch_size, patch_size), \n",
    "                              stride=(patch_size, patch_size), padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        patch_proj = self.proj(x)\n",
    "        patch_proj = rearrange(patch_proj, \"b c h w -> b (h w) c\")\n",
    "        return patch_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_patch_embedding(model):\n",
    "    proj = PatchEmbeddingScratch(in_channels=4, out_channels=768, patch_size=2)\n",
    "    proj.load_state_dict(model.x_embedder.state_dict())\n",
    "    with torch.no_grad():\n",
    "        tmp_state = torch.randn(5, 4, 16, 16)\n",
    "        print(proj(tmp_state).shape)\n",
    "        print(model.x_embedder(tmp_state).shape)\n",
    "        assert torch.allclose(proj(tmp_state), model.x_embedder(tmp_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 768])\n",
      "torch.Size([5, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "test_patch_embedding(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Position Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position Embedding\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    half_dim = embed_dim // 2\n",
    "    omega = np.arange(half_dim, dtype=np.float64) / half_dim\n",
    "    omega = 1. / 10000 ** omega  # (D/2,)\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    args = pos[:, None] * omega[None, :]  # (M, D/2), outer product\n",
    "    return np.concatenate([np.sin(args), np.cos(args)], axis=1)\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "    return np.concatenate([emb_h, emb_w], axis=1)\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False, extra_tokens=0, lewei_scale=1.0, base_size=8):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    if isinstance(grid_size, int):\n",
    "        grid_size = (grid_size, grid_size)\n",
    "    \n",
    "    grid_h = np.arange(grid_size[0], dtype=np.float32) / (grid_size[0] / base_size) / lewei_scale # note this is basically np.arange(grid_size[0]), remove the base_size which should be the same as the grid_size. \n",
    "    grid_w = np.arange(grid_size[1], dtype=np.float32) / (grid_size[1] / base_size) / lewei_scale\n",
    "    grid = np.meshgrid(grid_w, grid_h)  # here x coordinate goes first, y coordinate goes second\n",
    "    grid = np.stack(grid, axis=0)\n",
    "    grid = grid.reshape([2, grid_size[1], grid_size[0]])\n",
    "\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token and extra_tokens > 0:\n",
    "        pos_embed = np.concatenate([np.zeros([extra_tokens, embed_dim]), pos_embed], axis=0)\n",
    "    return pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 768)\n"
     ]
    }
   ],
   "source": [
    "def test_pos_embed(model):\n",
    "    pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "    print(pos_embed.shape)\n",
    "    assert torch.allclose(torch.tensor(pos_embed).to(torch.float32), \n",
    "                        model.pos_embed[0]), \"Position embedding does not match\"\n",
    "\n",
    "test_pos_embed(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize patch position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 768])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.8415,  0.8153,  0.7886,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.9093,  0.9442,  0.9698,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         ...,\n",
      "         [-0.9589, -0.9986, -0.9856,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.2794, -0.5348, -0.7393,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.6570,  0.3792,  0.0764,  ...,  1.0000,  1.0000,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(model.pos_embed.shape)\n",
    "print(model.pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figh, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "for i in range(25):\n",
    "    axs[i].imshow(model.pos_embed.reshape(8, 8, 768).\\\n",
    "                detach().cpu().numpy()[:, :, 384+i])\n",
    "    axs[i].set_title(f\"dim {i}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.suptitle(\"Patch Position Embedding from pretrained model PixArt\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAGsCAYAAAAfcpQMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0MUlEQVR4nO3deXhUVZ7/8U8lIZUASRQ6K4QkoAaNqCy2BBEXIBqQQdvGHQOMjAzYsgyIsV1QhGC7DN2tjcaho5hHoJ0A2j9lVQiNohIWBVRApUmExAzdmABKBaru7w+l2msWUktStyrv1/Oc55m6nlPnm9jjN+d7zr3XZhiGIQAAYGlhgQ4AAACcGQkbAIAgQMIGACAIkLABAAgCJGwAAIIACRsAgCBAwgYAIAiQsAEACAIkbAAAggAJGwCAIEDCBhASNm7cqBEjRiglJUU2m00rVqxo0fnS09Nls9nqtUmTJnn9ndu2bdPQoUN11llnqXPnzvqP//gPHTt2rMkx33zzjcaMGaOUlBS1b99e1113nfbt22fq8+WXX+rGG29UfHy8YmNjdfPNN+ubb77xeO533nlHAwYMUExMjJKTkzVz5kydOnXK1Ocvf/mLLrnkErVv315paWl66qmnvP59NMeJEyc0ZswY9erVSxEREbrhhhtadL5AImEDCAnHjx/XxRdfrOeee65V5tuyZYsqKyvdbe3atZKkUaNGNTomPT1dGzZsaPCfHTp0SEOGDNE555yjDz/8UKtWrdLu3bs1ZsyYRr/PMAzdcMMN+uqrr/TGG29o+/btSktL05AhQ3T8+HFJP/xecnJyZLPZ9O677+q9995TXV2dRowYIZfL1ey5P/nkEw0bNkzXXXedtm/friVLlujNN9/UAw884O6zcuVK3XHHHZowYYJ27dqlP/3pT3r22Wdb9N+J0+lUdHS07rvvPg0ZMqTF5rEEAwBCjCRj+fLlpmsOh8OYMWOGkZKSYrRv39745S9/aaxfv95vc06ePNno0aOH4XK5Gu2TlpbW6JwvvviikZCQYDidTve17du3G5KMffv2NThmz549hiRj165d7munTp0yOnXqZLz00kuGYRjG6tWrjbCwMKOmpsbd55///KchyVi7dm2z587Pzzf69etnmn/58uVGVFSUUVtbaxiGYdx2223Gr3/9a1Of//7v/za6du1q+r28+eabRp8+fQy73W5kZGQYs2bNMk6ePNnwL80DeXl5xsiRI33+HqtihQ2gTRg7dqzee+89LVmyRJ988olGjRrVYPnYG3V1dSouLta4ceNks9m8+g6Hw6HIyEiFhf3rP8vR0dGSpE2bNjU6RpKioqLc18LDwxUZGeke43A4ZLPZZLfb3X2ioqIUFhZm6nOmuR0Oh2me031OnDihrVu3Ntnn66+/1oEDByRJq1ev1p133qn77rtPn376qV588UW9/PLLmjNnTrN+T20ZCRtAyPvyyy+1ePFivf7667riiivUo0cPTZ8+XQMHDlRRUZHP379ixQp9++23TZavz+Saa65RVVWVnnrqKdXV1enIkSN68MEHJUmVlZUNjunZs6fS0tKUn5+vI0eOqK6uTvPmzVNVVZV7TP/+/dWhQwfNnDlT3333nY4fP64ZM2bI5XK5+zRn7muvvVbvv/++Fi9eLKfTqYMHD+qJJ56o12fZsmV655135HK5tHfvXs2fP9/UZ86cOXrggQeUl5en7t27a+jQoZo9e7ZefPFFr393bQUJG0DI27ZtmwzD0HnnnaeOHTu6W2lpqb788ktJ0t///vcGD5H9tN17770Nfv/ChQuVm5urlJQU0/UJEyaY5isvL1dubm69a5KUlZWlV155Rc8884zat2+vpKQkde/eXYmJiQoPD29w3nbt2qmkpER79+5Vp06d1L59e23YsEG5ubnuMfHx8Xr99df117/+VR07dlRcXJxqamrUp08fd5/mzJ2Tk6OnnnpKEyZMkN1u13nnnafhw4dLkrvP+PHjde+99+r6669XZGSk+vfvr1tvvdXUZ+vWrXr88cdNv4Px48ersrJS3333nSTpqquuavLfQ8eOHb34X0HwsxmGYQQ6CADwJ5vNpuXLl7tPDC9dulR33HGHdu/eXS/5dezYUUlJSTp58qQ7eTfm7LPPVmJiounagQMH1L17dy1btkwjR440/bPq6mrV1ta6P1911VV68sknddlll7mvpaenKyIiwjTum2++UYcOHWSz2RQbG6slS5Y0eZhNkmpqalRXV6f4+Hhddtll6tevn55//nlTn8OHDysiIkJnnXWWkpKS9F//9V+aMWOGR3MbhqHKykqdffbZ+vvf/64LLrhAH330kS699FJ3H6fTqaqqKsXHx+udd97RsGHD9M033yghIUHR0dF67LHH9Ktf/arez9C9e3eFhYWpvLzcnbwbEhYWpvPOO6/e9TFjxujbb79t8TsEAiXizF0AILj17t1bTqdT1dXVuuKKKxrs065dO/Xs2dPj7y4qKlJCQoJ7tflTCQkJSkhIcH+OiIhQly5ddM455zT5naf/KPjzn/+sqKgoDR069IxxxMXFSZL27dunsrIyzZ49u16fX/ziF5Kkd999V9XV1fq3f/s3j+e22WzuSsLixYuVmpqqPn36mPqEh4erS5cu7j7Z2dnu30OfPn20Z8+eJn8H3bp1O+PP2xaRsAGEhGPHjumLL75wf96/f7927NihTp066bzzztMdd9yhu+66S88884x69+6tw4cP691331WvXr00bNgwr+Z0uVwqKipSXl5evVWyN5577jkNGDBAHTt21Nq1azVjxgzNmzdPZ511lrtPz549VVBQoBtvvFGS9Prrrys+Pl7dunXTzp07NXnyZN1www3KyclxjykqKtL555+v+Ph4bd68WZMnT9bUqVOVmZnp0dxPPfWUrrvuOoWFhWnZsmWaN2+e/vKXv7irFocPH9b//u//6qqrrtKJEydUVFSk119/XaWlpe7veOSRR3T99dcrNTVVo0aNUlhYmD755BPt3LnTvSfuqU8//VR1dXX65z//qaNHj2rHjh2SpEsuucSr77OswB5SBwD/WL9+vSGpXsvLyzMMwzDq6uqMRx55xEhPTzfatWtnJCUlGTfeeKPxySefeD3n6tWrDUnGnj17mtW/qdu6DMMwRo8ebXTq1MmIjIw0LrroImPRokX1+kgyioqK3J9///vfG127djXatWtndOvWzXjooYcMh8NhGjNz5kwjMTHRaNeunXHuuecazzzzTL3bz5oz99VXX23ExcUZUVFRxmWXXWa8/fbbpn/+f//3f0b//v2NDh06GO3btzcGDx5sfPDBB/W+Z9WqVcaAAQOM6OhoIzY21vjlL39pFBYWNvp7OZO0tLQG/92HGvawAQD40caNG/XUU09p69atqqysNJ2FkH7Yw3/sscdUWFioI0eO6LLLLtPzzz+vrKysJr+3pKREDz/8sL788kv16NFDc+bMcVdJmotT4gAA/OhMT8z73e9+535625YtW5SUlKShQ4fq6NGjjX7n5s2bdcstt2j06NH6+OOPNXr0aN1888368MMPPYqNFTYAAA34+d0GhmEoJSVFU6ZM0cyZMyX98LCYxMREPfnkk7rnnnsa/J5bbrlFtbW1Wrlypfvaddddp7PPPluLFy9udjytfujM5XLp0KFDiomJ8fqJQACAwDAMQ0ePHlVKSorpyWj+duLECdXV1fn8PYZh1Ms1drvd9OS35tq/f7+qqqpMB/rsdruuvPJKvf/++40m7M2bN2vq1Kmma9dee637oTLN1eoJ+9ChQ0pNTW3taQEAflRRUaGuXbu2yHefOHFCGWkdVVXt9Pm7OnbsWO+tY48++qhmzZrl8XdVVVVJUr178RMTE92PXm1sXENjTn9fc7V6wo6JiZEkHdiWrtiObKEDQDCpPeZSWp+/u/9b3hLq6upUVe3U/q1pio3xPk/UHnUpo+8BVVRUKDY21n3dm9X1T/18xd7QKt4fY36u1RP26QBjO4b59C8CABA4rbGlGRvjnzwRGxtrStjeSkpKkvTDijk5Odl9vbq6ut4K+ufjfr6aPtOYhpAxAQCW5DRcPjd/ysjIUFJSkvvd59IP1YDS0lINGDCg0XHZ2dmmMZK0Zs2aJsc0hCedAQAsySVDLnl/I5M3Y5t6Yl63bt00ZcoUzZ07V+eee67OPfdczZ07V+3bt9ftt9/uHnPXXXepS5cuKigokCRNnjxZgwYN0pNPPqmRI0fqjTfe0Lp16xp9bWpjSNgAAEtyySVf1sjejC4rK9PVV1/t/jxt2jRJUl5enl5++WXdf//9+v777zVx4kT3g1PWrFlj2tMvLy83naAfMGCAlixZooceekgPP/ywevTooaVLl5peAtMcrX4fdm1treLi4nRkb3f2sAEgyNQedens875STU2NX/aFG5zjxzxxaE9Xnw+dpWR+3aKxtiZW2AAAS3Iahpw+rCl9GWtFJGwAgCUFYg/byqhJAwAQBFhhAwAsySVDTlbYbiRsAIAlURI3oyQOAEAQYIUNALAkTombkbABAJbk+rH5Mj6UUBIHACAIsMIGAFiS08dT4r6MtSISNgDAkpzGD82X8aGEhA0AsCT2sM282sP+05/+pIyMDEVFRalv377629/+5u+4AADAT3icsJcuXaopU6bot7/9rbZv364rrrhCubm5Ki8vb4n4AABtlEs2OX1oLtkC/SP4lccJ+9lnn9W///u/6+6779b555+v+fPnKzU1VQsWLGiJ+AAAbZTL8L2FEo8Sdl1dnbZu3aqcnBzT9ZycHL3//vsNjnE4HKqtrTU1AADgGY8S9uHDh+V0OpWYmGi6npiYqKqqqgbHFBQUKC4uzt1SU1O9jxYA0Gb4Ug4/3UKJV4fObDbzL8EwjHrXTsvPz1dNTY27VVRUeDMlAKCNIWGbeXRb1y9+8QuFh4fXW01XV1fXW3WfZrfbZbfbvY8QAAB4tsKOjIxU3759tXbtWtP1tWvXasCAAX4NDADQtrkMm88tlHj84JRp06Zp9OjR6tevn7Kzs1VYWKjy8nJNmDChJeIDALRRvpa123RJXJJuueUW/eMf/9Djjz+uyspKXXjhhXr77beVlpbWEvEBAAB5+WjSiRMnauLEif6OBQAAN6fC5PThpZJOP8ZiBTxLHABgSYaP+9BGW9/DBgCgNbCHbeZ9rQEAALQaVtgAAEtyGmFyGj7sYYfYs8RJ2AAAS3LJJpcPhWCXQitjUxIHACAIsMIGAFgSh87MSNgAAEvyfQ+bkjgAAGhlrLABAJb0w6Ez78vavoy1IhI2AMCSXD4+mpRT4gAAoNWxwgYAWBKHzsxI2AAAS3IpjAen/AQJGwBgSU7DJqcPb9zyZawVsYcNAEAQYIUNALAkp4+nxJ2UxAEAaHkuI0wuHw6duULs0BklcQAAggArbACAJVESNyNhAwAsySXfTnq7/BeKJVASBwAgCLDCBgBYku8PTgmtNSkJGwBgSb4/mjS0EnZo/TQAAIQoVtgAAEvifdhmJGwAgCVREjcjYQMALMn3+7BDK2GH1k8DAIAPjh49qilTpigtLU3R0dEaMGCAtmzZ0mj/DRs2yGaz1Wuff/6532NjhQ0AsCSXYZPLlweneDH27rvv1q5du/Tqq68qJSVFxcXFGjJkiD799FN16dKl0XF79uxRbGys+3N8fLxXMTeFFTYAwJJcP5bEvW2e3of9/fffq6SkRL/73e80aNAgnXPOOZo1a5YyMjK0YMGCJscmJCQoKSnJ3cLDw3350RtEwgYAhLTa2lpTczgcDfY7deqUnE6noqKiTNejo6O1adOmJufo3bu3kpOTNXjwYK1fv95vsf8UCRsAYEmnX6/pS5Ok1NRUxcXFuVtBQUGD88XExCg7O1uzZ8/WoUOH5HQ6VVxcrA8//FCVlZUNjklOTlZhYaFKSkq0bNkyZWZmavDgwdq4caPffx/sYQMALMkpm5w+3Et9emxFRYVpf9lutzc65tVXX9W4cePUpUsXhYeHq0+fPrr99tu1bdu2BvtnZmYqMzPT/Tk7O1sVFRV6+umnNWjQIK9jbwgrbABASIuNjTW1phJ2jx49VFpaqmPHjqmiokIfffSRTp48qYyMjGbP179/f+3bt88foZt4nLA3btyoESNGKCUlRTabTStWrPB7UAAA+Ksk7o0OHTooOTlZR44c0erVqzVy5Mhmj92+fbuSk5O9nrsxHpfEjx8/rosvvlhjx47VTTfd5PeAAACQJKfkY0ncc6tXr5ZhGMrMzNQXX3yhGTNmKDMzU2PHjpUk5efn6+DBg1q0aJEkaf78+UpPT1dWVpbq6upUXFyskpISlZSUeB13YzxO2Lm5ucrNzfV7IAAABFpNTY3y8/P19ddfq1OnTrrppps0Z84ctWvXTpJUWVmp8vJyd/+6ujpNnz5dBw8eVHR0tLKysvTWW29p2LBhfo+txQ+dORwO0xH62tralp4SABACfC1rezP25ptv1s0339zoP3/55ZdNn++//37df//9Hs/jjRY/dFZQUGA6Tp+amtrSUwIAQsDpl3/40kJJi/80+fn5qqmpcbeKioqWnhIAEAKMH1+v6W0zeL2mZ+x2e5NH6AEAwJnx4BQAgCXxPmwzjxP2sWPH9MUXX7g/79+/Xzt27FCnTp3UrVs3vwYHAGi7AvG2LivzOGGXlZXp6quvdn+eNm2aJCkvL6/e6TkAAOAfHifsq666SoZhtEQsAAC4nX5Npi/jQwl72AAAS6IkbhZaf34AABCiWGEDACzJpTC5fFhX+jLWikjYAABLcho2OX0oa/sy1opC688PAABCFCtsAIAlcejMjIQNALAkw8e3dRlt/UlnAAC0BqdscvrwAg9fxlpRaP35AQBAiGKFDQCwJJfh2z60K8QeyknCBgBYksvHPWxfxlpRaP00AACEKFbYAABLcskmlw8Hx3wZa0UkbACAJfGkMzNK4gAABAFW2AAAS+LQmRkJGwBgSS75+GjSENvDDq0/PwAACFGssAEAlmT4eErcCLEVNgkbAGBJvK3LjIQNALAkDp2ZhdZPAwBAiGKFDQCwJEriZiRsAIAl8WhSM0riAAAEAVbYAABLoiRuRsIGAFgSCduMkjgAAEGAFTYAwJJYYZuRsAEAlkTCNqMkDgBAEGCFDQCwJEO+3Utt+C8USyBhAwAsiZK4GQkbAGBJJGwz9rABAAgCHiXsgoICXXrppYqJiVFCQoJuuOEG7dmzp6ViAwC0YadX2L60UOJRwi4tLdWkSZP0wQcfaO3atTp16pRycnJ0/PjxlooPANBGkbDNPNrDXrVqlelzUVGREhIStHXrVg0aNMivgQEAgH/x6dBZTU2NJKlTp06N9nE4HHI4HO7PtbW1vkwJAGgjDMMmw4dVsi9jrcjrQ2eGYWjatGkaOHCgLrzwwkb7FRQUKC4uzt1SU1O9nRIA0Iacfh+2Ly2UeJ2w7733Xn3yySdavHhxk/3y8/NVU1PjbhUVFd5OCQBAm+VVSfw3v/mN3nzzTW3cuFFdu3Ztsq/dbpfdbvcqOABA28V92GYeJWzDMPSb3/xGy5cv14YNG5SRkdFScQEA2jj2sM08StiTJk3Sa6+9pjfeeEMxMTGqqqqSJMXFxSk6OrpFAgQAAB7uYS9YsEA1NTW66qqrlJyc7G5Lly5tqfgAAG1UIO7DPnr0qKZMmaK0tDRFR0drwIAB2rJlS5NjSktL1bdvX0VFRal79+564YUXvP2Rm+RxSRwAgNYQiJL43XffrV27dunVV19VSkqKiouLNWTIEH366afq0qVLvf779+/XsGHDNH78eBUXF+u9997TxIkTFR8fr5tuusnr2BvCs8QBAJZk+Li69jRhf//99yopKdHvfvc7DRo0SOecc45mzZqljIwMLViwoMExL7zwgrp166b58+fr/PPP1913361x48bp6aef9sevwISEDQAIabW1tab204d5/dSpU6fkdDoVFRVluh4dHa1NmzY1OGbz5s3KyckxXbv22mtVVlamkydP+ucH+BEJGwBgSYYkw/Ch/fg9qamppgd4FRQUNDhfTEyMsrOzNXv2bB06dEhOp1PFxcX68MMPVVlZ2eCYqqoqJSYmmq4lJibq1KlTOnz4sB9/G7wPGwBgUS7ZZPPhaWWnn3RWUVGh2NhY9/Wmng3y6quvaty4cerSpYvCw8PVp08f3X777dq2bVujY2w2c4ynz3v9/LqvWGEDAEJabGysqTWVsHv06KHS0lIdO3ZMFRUV+uijj3Ty5MlGnzuSlJTkvsX5tOrqakVERKhz585+/TlI2AAASzp9StyX5q0OHTooOTlZR44c0erVqzVy5MgG+2VnZ2vt2rWma2vWrFG/fv3Url07r+dvCAkbAGBJgbgPe/Xq1Vq1apX279+vtWvX6uqrr1ZmZqbGjh0r6Yf3Y9x1113u/hMmTNCBAwc0bdo0ffbZZ/rzn/+shQsXavr06X77PZxGwgYA4Ec1NTWaNGmSevbsqbvuuksDBw7UmjVr3KvlyspKlZeXu/tnZGTo7bff1oYNG3TJJZdo9uzZ+sMf/uD3e7AlyWa08tNQamtrFRcXpyN7uys2hr8XACCY1B516ezzvlJNTY3pIJdf5/gxT2QtnaHw9t6/PMr5nUO7b3mqRWNtTZwSBwBYEi//MGOJCwBAEGCFDQCwJFbYZiRsAIAluQybbD4kXW9OiVsZCRsAYEmnHzHqy/hQwh42AABBgBU2AMCSflhh+7KH7cdgLCBgCXv2/10g+/f+fWwbAKBlOY6dlPRVq8zFoTMzSuIAAAQBSuIAAEsy9K93Wns7PpSQsAEAlkRJ3IySOAAAQYAVNgDAmqiJm5CwAQDW5GNJXCFWEidhAwAsiSedmbGHDQBAEGCFDQCwJE6Jm5GwAQDWZNh824cOsYRNSRwAgCDAChsAYEkcOjMjYQMArIn7sE0oiQMAEARYYQMALIlT4mYkbACAdYVYWdsXlMQBAAgCrLABAJZESdzMoxX2ggULdNFFFyk2NlaxsbHKzs7WypUrWyo2AEBbZvihhRCPEnbXrl01b948lZWVqaysTNdcc41Gjhyp3bt3t1R8AIA2y+aHFjo8KomPGDHC9HnOnDlasGCBPvjgA2VlZfk1MAAA8C9e72E7nU69/vrrOn78uLKzsxvt53A45HA43J9ra2u9nRIA0Jbw4BQTj0+J79y5Ux07dpTdbteECRO0fPlyXXDBBY32LygoUFxcnLulpqb6FDAAoI1gD9vE44SdmZmpHTt26IMPPtB//ud/Ki8vT59++mmj/fPz81VTU+NuFRUVPgUMAEBb5HFJPDIyUuecc44kqV+/ftqyZYt+//vf68UXX2ywv91ul91u9y1KAEDbw+s1TXy+D9swDNMeNQAA/sDbusw8StgPPvigcnNzlZqaqqNHj2rJkiXasGGDVq1a1VLxAQAAeZiwv/nmG40ePVqVlZWKi4vTRRddpFWrVmno0KEtFR8AoK3ilLiJRwl74cKFLRUHAABm7GGb8PIPAACCAC//AABYks34ofkyPpSQsAEA1sQetgkJGwBgTexhm7CHDQBAEGCFDQCwJkriJiRsAIA1kbBNKIkDABAEWGEDAKyJFbYJCRsAYE2cEjehJA4AQBBghQ0AsCSedGZGwgYAWBN72CaUxAEACAIkbAAAJJ06dUoPPfSQMjIyFB0dre7du+vxxx+Xy+VqdMyGDRtks9nqtc8//9zv8VESBwBYkk0+7mF72P/JJ5/UCy+8oFdeeUVZWVkqKyvT2LFjFRcXp8mTJzc5ds+ePYqNjXV/jo+P9yLipgUsYS/7/BKFtY8K1PQAAC+4vjsh6f+1zmStfFvX5s2bNXLkSA0fPlySlJ6ersWLF6usrOyMYxMSEnTWWWd5E2WzURIHAIS02tpaU3M4HA32GzhwoN555x3t3btXkvTxxx9r06ZNGjZs2Bnn6N27t5KTkzV48GCtX7/er/GfRkkcAGBNfjolnpqaarr86KOPatasWfW6z5w5UzU1NerZs6fCw8PldDo1Z84c3XbbbY1OkZycrMLCQvXt21cOh0OvvvqqBg8erA0bNmjQoEE+BF8fCRsAYE1+StgVFRWm/WW73d5g96VLl6q4uFivvfaasrKytGPHDk2ZMkUpKSnKy8trcExmZqYyMzPdn7Ozs1VRUaGnn36ahA0AgCdiY2NNCbsxM2bM0AMPPKBbb71VktSrVy8dOHBABQUFjSbshvTv31/FxcVex9sYEjYAwJJa+0ln3333ncLCzEe7wsPDm7ytqyHbt29XcnKyZ5M3AwkbAGBNrfyksxEjRmjOnDnq1q2bsrKytH37dj377LMaN26cu09+fr4OHjyoRYsWSZLmz5+v9PR0ZWVlqa6uTsXFxSopKVFJSYkPgTeMhA0AgKQ//vGPevjhhzVx4kRVV1crJSVF99xzjx555BF3n8rKSpWXl7s/19XVafr06Tp48KCio6OVlZWlt956q1knyz1lMwyjVZ+2Wltbq7i4OKUvfIj7sAEgyLi+O6G///sTqqmpada+sDfceWL2HIVFeZ8nXCdO6O8P/7ZFY21NrLABAJbE27rMeHAKAABBgBU2AMCaWvnRpFZHwgYAWBPvwzYhYQMALIk9bDP2sAEACAKssAEA1kRJ3ISEDQCwJh9L4qGWsCmJAwAQBFhhAwCsiZK4CQkbAGBNJGwTn0riBQUFstlsmjJlip/CAQAADfF6hb1lyxYVFhbqoosu8mc8AABI4j7sn/NqhX3s2DHdcccdeumll3T22Wf7OyYAAPAzXiXsSZMmafjw4RoyZMgZ+zocDtXW1poaAADwjMcl8SVLlmjbtm3asmVLs/oXFBToscce8zgwAEAbx6EzE49W2BUVFZo8ebKKi4sV1cyXiufn56umpsbdKioqvAoUANC2nN7D9qWFEo9W2Fu3blV1dbX69u3rvuZ0OrVx40Y999xzcjgcCg8PN42x2+2y2+3+iRYA0LaEWNL1hUcJe/Dgwdq5c6fp2tixY9WzZ0/NnDmzXrIGAAD+4VHCjomJ0YUXXmi61qFDB3Xu3LnedQAAfMIetglPOgMAWBL3YZv5nLA3bNjghzAAAEBTWGEDAKyJkrgJCRsAYEmUxM14HzYAAEGAFTYAwJooiZuQsAEA1kTCNqEkDgBAEGCFDQCwJA6dmZGwAQDWREnchIQNALAmErYJe9gAAAQBVtgAAEtiD9uMhA0AsCZK4iaUxAEACAKssAEAlkRJ3IyEDQCwJkriJgFL2JG72ivcHhWo6QEAXnA62EkNFFbYAABrYoVtQsIGAFiS7cfmy/hQQm0DAIAgwAobAGBNlMRNSNgAAEviti4zEjYAwJpYYZuwhw0AQBBghQ0AsK4QWyX7goQNALAk9rDNKIkDABAEWGEDAKyJQ2cmJGwAgCVREjejJA4AQBAgYQMArMnwQ/PAqVOn9NBDDykjI0PR0dHq3r27Hn/8cblcribHlZaWqm/fvoqKilL37t31wgsveDZxM1ESBwBYUmuXxJ988km98MILeuWVV5SVlaWysjKNHTtWcXFxmjx5coNj9u/fr2HDhmn8+PEqLi7We++9p4kTJyo+Pl433XST98E3gIQNAICkzZs3a+TIkRo+fLgkKT09XYsXL1ZZWVmjY1544QV169ZN8+fPlySdf/75Kisr09NPP+33hE1JHABgTX4qidfW1pqaw+FocLqBAwfqnXfe0d69eyVJH3/8sTZt2qRhw4Y1GuLmzZuVk5NjunbttdeqrKxMJ0+e9O7nbgQrbACANfnptq7U1FTT5UcffVSzZs2q133mzJmqqalRz549FR4eLqfTqTlz5ui2225rdIqqqiolJiaariUmJurUqVM6fPiwkpOTffgBzEjYAABL8tcedkVFhWJjY93X7XZ7g/2XLl2q4uJivfbaa8rKytKOHTs0ZcoUpaSkKC8vr/F5bDbTZ8MwGrzuK49K4rNmzZLNZjO1pKQkvwYEAIA/xcbGmlpjCXvGjBl64IEHdOutt6pXr14aPXq0pk6dqoKCgka/OykpSVVVVaZr1dXVioiIUOfOnf36c3i8ws7KytK6devcn8PDw/0aEAAAklr9SWffffedwsLM69jw8PAmb+vKzs7WX//6V9O1NWvWqF+/fmrXrp1nAZyBxwk7IiKCVTUAoMXZDEM2w/uM7enYESNGaM6cOerWrZuysrK0fft2Pfvssxo3bpy7T35+vg4ePKhFixZJkiZMmKDnnntO06ZN0/jx47V582YtXLhQixcv9jruxnicsPft26eUlBTZ7XZddtllmjt3rrp3795of4fDYTqRV1tb612kAAC0oD/+8Y96+OGHNXHiRFVXVyslJUX33HOPHnnkEXefyspKlZeXuz9nZGTo7bff1tSpU/X8888rJSVFf/jDH/x+S5ck2Qyj+X+CrFy5Ut99953OO+88ffPNN3riiSf0+eefa/fu3Y3W6mfNmqXHHnus3vXzps5VuD3K+8gBAK3O6Tihvf/9oGpqakwHufyptrZWcXFxuuTOOQqP9D5POOtOaEfxb1s01tbk0aGz3Nxc3XTTTerVq5eGDBmit956S5L0yiuvNDomPz9fNTU17lZRUeFbxACANuH0KXFfWijx6bauDh06qFevXtq3b1+jfex2e6Mn8gAAQPP49KQzh8Ohzz77zK83hgMAIKnVX/5hdR4l7OnTp6u0tFT79+/Xhx9+qF//+teqra1t8oZyAAC8QUnczKOS+Ndff63bbrtNhw8fVnx8vPr3768PPvhAaWlpLRUfAACQhwl7yZIlLRUHAABmrfzgFKvjWeIAAEtq7fdhWx0JGwBgTaywTXgfNgAAQYAVNgDAskKtrO0LEjYAwJoM44fmy/gQQkkcAIAgwAobAGBJnBI3I2EDAKyJU+ImlMQBAAgCrLABAJZkc/3QfBkfSkjYAABroiRuQkkcAIAgwAobAGBJnBI3I2EDAKyJB6eYkLABAJbECtssYAk7YZtDERG2QE0PAPDCqVMO7Q10EG0UK2wAgDVxStyEhA0AsCRK4mbc1gUAQBBghQ0AsCZOiZuQsAEAlkRJ3IySOAAAQYAVNgDAmjglbkLCBgBYEiVxM0riAAAEAVbYAABrchk/NF/GhxASNgDAmtjDNiFhAwAsySYf97D9Fok1sIcNAEAQYIUNALAmnnRmQsIGAFgSt3WZURIHACAIsMIGAFgTp8RNSNgAAEuyGYZsPuxD+zLWiiiJAwAQBDxO2AcPHtSdd96pzp07q3379rrkkku0devWlogNANCWufzQQohHJfEjR47o8ssv19VXX62VK1cqISFBX375pc4666wWCg8A0FZREjfzKGE/+eSTSk1NVVFRkftaenq6v2MCAAA/41FJ/M0331S/fv00atQoJSQkqHfv3nrppZeaHONwOFRbW2tqAACckeGHFkI8SthfffWVFixYoHPPPVerV6/WhAkTdN9992nRokWNjikoKFBcXJy7paam+hw0AKANOP2kM19aCPEoYbtcLvXp00dz585V7969dc8992j8+PFasGBBo2Py8/NVU1PjbhUVFT4HDQAIfaefdOZLCyUeJezk5GRdcMEFpmvnn3++ysvLGx1jt9sVGxtragAAwDMeHTq7/PLLtWfPHtO1vXv3Ki0tza9BAQDAyz/MPErYU6dO1YABAzR37lzdfPPN+uijj1RYWKjCwsKWig8A0EbZXD80X8aHEo9K4pdeeqmWL1+uxYsX68ILL9Ts2bM1f/583XHHHS0VHwAAkBdPOrv++uu1c+dOnThxQp999pnGjx/fEnEBANq6Vj4lnp6eLpvNVq9NmjSpwf4bNmxosP/nn3/uj5++Hl7+AQCwplZ+W9eWLVvkdDrdn3ft2qWhQ4dq1KhRTY7bs2eP6UB1fHy8ZxM3EwkbAADVT7Tz5s1Tjx49dOWVVzY5LiEhoVUe0c3bugAAlnT6WeK+NEn1nrbpcDjOOHddXZ2Ki4s1btw42Wy2Jvv27t1bycnJGjx4sNavX++Xn70hJGwAgDX5aQ87NTXV9MTNgoKCM069YsUKffvttxozZkyjfZKTk1VYWKiSkhItW7ZMmZmZGjx4sDZu3Oiv34AJJXEAQEirqKgw7THb7fYzjlm4cKFyc3OVkpLSaJ/MzExlZma6P2dnZ6uiokJPP/20Bg0a5FvQDSBhAwCsyZBv77T+8dCZp0/ZPHDggNatW6dly5Z5PGX//v1VXFzs8bjmIGEDACwpUO/DLioqUkJCgoYPH+7x2O3btys5Odmrec+EhA0AsCZDPj6a1PMhLpdLRUVFysvLU0SEOUXm5+fr4MGD7jdUzp8/X+np6crKynIfUispKVFJSYn3MTeBhA0AwI/WrVun8vJyjRs3rt4/q6ysNL3sqq6uTtOnT9fBgwcVHR2trKwsvfXWWxo2bFiLxEbCBgBYUwBe/pGTkyOjkXEvv/yy6fP999+v+++/35vIvELCBgBYk0tS07dAn3l8COE+bAAAggArbACAJQXqlLhVkbABANYUgD1sK6MkDgBAEGCFDQCwJlbYJgFL2BGlOxRhaxeo6QEA3jBOtuJcJOyfoiQOAEAQoCQOALAm7sM2IWEDACyJ27rMSNgAAGtiD9uEPWwAAIIAK2wAgDW5DMnmwyrZFVorbBI2AMCaKImbUBIHACAIsMIGAFiUjytshdYKm4QNALAmSuImlMQBAAgCrLABANbkMuRTWZtT4gAAtALD9UPzZXwIoSQOAEAQYIUNALAmDp2ZkLABANbEHrYJCRsAYE2ssE3YwwYAIAh4lLDT09Nls9nqtUmTJrVUfACAtsrQv1bZXrVA/wD+5VFJfMuWLXI6ne7Pu3bt0tChQzVq1Ci/BwYAaOMoiZt4lLDj4+NNn+fNm6cePXroyiuv9GtQAADAzOtDZ3V1dSouLta0adNks9ka7edwOORwONyfa2trvZ0SANCWuFySfHj4iYsHp0iSVqxYoW+//VZjxoxpsl9BQYHi4uLcLTU11dspAQBtiU/7176+6ct6vE7YCxcuVG5urlJSUprsl5+fr5qaGnerqKjwdkoAANosr0riBw4c0Lp167Rs2bIz9rXb7bLb7d5MAwBoyzh0ZuJVwi4qKlJCQoKGDx/u73gAAPgBTzoz8bgk7nK5VFRUpLy8PEVE8KA0AABag8cZd926dSovL9e4ceNaIh4AACRJhuGS4cMrMn0Za0UeJ+ycnBwZIbYvAACwIMPwrawdYrmKmjYAwJoMH/ewQyxh8/IPAACCACtsAIA1uVySzYd96La+hw0AQKugJG5CSRwAgCDAChsAYEmGyyXDh5J4m7+tCwCAVkFJ3ISSOAAAQYAVNgDAmlyGZGOFfRoJGwBgTYYhyZfbukIrYVMSBwAgCLDCBgBYkuEyZPhQEg+1916QsAEA1mS45FtJnNu6AABocaywzdjDBgAgCLT6Cvv0XzyndNKn++EBAK3vlE5Kap3V6ynD4VNZ+3SsoaLVE/bRo0clSZv0dmtPDQDwk6NHjyouLq5FvjsyMlJJSUnaVOV7nkhKSlJkZKQfogo8m9HKRX6Xy6VDhw4pJiZGNpvNr99dW1ur1NRUVVRUKDY21q/f3ZKIu3URd+sL1tiJuz7DMHT06FGlpKQoLKzldlVPnDihuro6n78nMjJSUVFRfogo8Fp9hR0WFqauXbu26ByxsbFB9f9cpxF36yLu1hessRO3WUutrH8qKioqZBKtv3DoDACAIEDCBgAgCIRUwrbb7Xr00Udlt9sDHYpHiLt1EXfrC9bYiRtW0uqHzgAAgOdCaoUNAECoImEDABAESNgAAAQBEjYAAEEgZBL2n/70J2VkZCgqKkp9+/bV3/72t0CHdEYbN27UiBEjlJKSIpvNphUrVgQ6pGYpKCjQpZdeqpiYGCUkJOiGG27Qnj17Ah3WGS1YsEAXXXSR+2ES2dnZWrlyZaDD8lhBQYFsNpumTJkS6FCaNGvWLNlsNlNLSkoKdFjNcvDgQd15553q3Lmz2rdvr0suuURbt24NdFhnlJ6eXu93brPZNGnSpECHBj8IiYS9dOlSTZkyRb/97W+1fft2XXHFFcrNzVV5eXmgQ2vS8ePHdfHFF+u5554LdCgeKS0t1aRJk/TBBx9o7dq1OnXqlHJycnT8+PFAh9akrl27at68eSorK1NZWZmuueYajRw5Urt37w50aM22ZcsWFRYW6qKLLgp0KM2SlZWlyspKd9u5c2egQzqjI0eO6PLLL1e7du20cuVKffrpp3rmmWd01llnBTq0M9qyZYvp97127VpJ0qhRowIcGfzCCAG//OUvjQkTJpiu9ezZ03jggQcCFJHnJBnLly8PdBheqa6uNiQZpaWlgQ7FY2effbbxP//zP4EOo1mOHj1qnHvuucbatWuNK6+80pg8eXKgQ2rSo48+alx88cWBDsNjM2fONAYOHBjoMPxi8uTJRo8ePQyXyxXoUOAHQb/Crqur09atW5WTk2O6npOTo/fffz9AUbUtNTU1kqROnToFOJLmczqdWrJkiY4fP67s7OxAh9MskyZN0vDhwzVkyJBAh9Js+/btU0pKijIyMnTrrbfqq6++CnRIZ/Tmm2+qX79+GjVqlBISEtS7d2+99NJLgQ7LY3V1dSouLta4ceP8/qIlBEbQJ+zDhw/L6XQqMTHRdD0xMVFVVVUBiqrtMAxD06ZN08CBA3XhhRcGOpwz2rlzpzp27Ci73a4JEyZo+fLluuCCCwId1hktWbJE27ZtU0FBQaBDabbLLrtMixYt0urVq/XSSy+pqqpKAwYM0D/+8Y9Ah9akr776SgsWLNC5556r1atXa8KECbrvvvu0aNGiQIfmkRUrVujbb7/VmDFjAh0K/KTV39bVUn7+F6RhGPxV2QruvfdeffLJJ9q0aVOgQ2mWzMxM7dixQ99++61KSkqUl5en0tJSSyftiooKTZ48WWvWrAmqtxfl5ua6/+9evXopOztbPXr00CuvvKJp06YFMLKmuVwu9evXT3PnzpUk9e7dW7t379aCBQt01113BTi65lu4cKFyc3OVkpIS6FDgJ0G/wv7FL36h8PDweqvp6urqeqtu+NdvfvMbvfnmm1q/fn2LvzLVXyIjI3XOOeeoX79+Kigo0MUXX6zf//73gQ6rSVu3blV1dbX69u2riIgIRUREqLS0VH/4wx8UEREhp9MZ6BCbpUOHDurVq5f27dsX6FCalJycXO8PuPPPP9/yh1h/6sCBA1q3bp3uvvvuQIcCPwr6hB0ZGam+ffu6T0OetnbtWg0YMCBAUYU2wzB07733atmyZXr33XeVkZER6JC8ZhiGHA5HoMNo0uDBg7Vz507t2LHD3fr166c77rhDO3bsUHh4eKBDbBaHw6HPPvtMycnJgQ6lSZdffnm92xT37t2rtLS0AEXkuaKiIiUkJGj48OGBDgV+FBIl8WnTpmn06NHq16+fsrOzVVhYqPLyck2YMCHQoTXp2LFj+uKLL9yf9+/frx07dqhTp07q1q1bACNr2qRJk/Taa6/pjTfeUExMjLu6ERcXp+jo6ABH17gHH3xQubm5Sk1N1dGjR7VkyRJt2LBBq1atCnRoTYqJial3PqBDhw7q3Lmzpc8NTJ8+XSNGjFC3bt1UXV2tJ554QrW1tcrLywt0aE2aOnWqBgwYoLlz5+rmm2/WRx99pMLCQhUWFgY6tGZxuVwqKipSXl6eIiJC4j/xOC2wh9T95/nnnzfS0tKMyMhIo0+fPkFxi9H69esNSfVaXl5eoENrUkMxSzKKiooCHVqTxo0b5/7fSHx8vDF48GBjzZo1gQ7LK8FwW9ctt9xiJCcnG+3atTNSUlKMX/3qV8bu3bsDHVaz/PWvfzUuvPBCw263Gz179jQKCwsDHVKzrV692pBk7NmzJ9ChwM94vSYAAEEg6PewAQBoC0jYAAAEARI2AABBgIQNAEAQIGEDABAESNgAAAQBEjYAAEGAhA0AQBAgYQMAEARI2AAABAESNgAAQYCEDQBAEPj/4RCSpLOjiPgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.pos_embed.reshape(8, 8, 768).\\\n",
    "            detach().cpu().numpy()[:, :, -2])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time step embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Embedding\n",
    "\n",
    "def get_sinusoidal_embedding(t, dim, max_period=10000, device=\"cpu\"):\n",
    "    half = dim // 2\n",
    "    # freqs = torch.float_power(max_period, -torch.arange(start=0, end=half, dtype=torch.float32, device=device) / half).to(torch.float32)\n",
    "    freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32, device=device) / half)\n",
    "    args = t[:, None].float() * freqs[None]\n",
    "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "    if dim % 2:\n",
    "        # in case the dimension is odd, add a zero embedding for the last dimension\n",
    "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "class TimeEmbeddingScratch(nn.Module):\n",
    "    def __init__(self, hidden_dim, freq_embedding_size=256, max_period=10000):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(freq_embedding_size, hidden_dim, bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim, bias=True),\n",
    "        )\n",
    "        self.freq_embedding_size = freq_embedding_size\n",
    "        self.max_period = max_period\n",
    "        \n",
    "    def forward(self, t):\n",
    "        sin_emb = get_sinusoidal_embedding(t, self.freq_embedding_size, self.max_period, device=t.device) #.to(self.dtype)\n",
    "        return self.mlp(sin_emb)\n",
    "    \n",
    "\n",
    "def get_time_blocks(hidden_size):\n",
    "    return nn.Sequential(\n",
    "        nn.SiLU(),\n",
    "        nn.Linear(hidden_size, hidden_size * 6, bias=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_blocks(model):\n",
    "    t_blocks = get_time_blocks(768)\n",
    "    # Test the time embedding\n",
    "    t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "    tmp_state = torch.randn(5, 768)\n",
    "    assert torch.allclose(t_blocks(tmp_state), model.t_block(tmp_state))\n",
    "    \n",
    "    \n",
    "def test_time_embedding_and_blocks(model):\n",
    "    tmp_state = torch.randint(0, 1000, (10,))\n",
    "    t_emb = TimeEmbeddingScratch(768, )\n",
    "    t_emb.load_state_dict(model.t_embedder.state_dict())\n",
    "    assert torch.allclose(t_emb(tmp_state), model.t_embedder(tmp_state)), \"Time embedding does not match\"\n",
    "    t_blocks = get_time_blocks(768)\n",
    "    t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "    assert torch.allclose(t_blocks(t_emb(tmp_state)), \n",
    "                          model.t_block(model.t_embedder(tmp_state))), \"Time blocks does not match\"\n",
    "\n",
    "\n",
    "test_time_embedding_and_blocks(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class CaptionEmbeddingScratch(nn.Module):\n",
    "    def __init__(self, in_features=4096, hidden_features=768, max_length=20):\n",
    "        super().__init__()\n",
    "        self.y_proj = nn.Sequential(OrderedDict([\n",
    "            (\"fc1\", nn.Linear(in_features, hidden_features, bias=True)),\n",
    "            (\"act\", nn.GELU(approximate='tanh')),\n",
    "            (\"drop1\", nn.Dropout(p=0)),\n",
    "            (\"fc2\", nn.Linear(hidden_features, hidden_features, bias=True)),\n",
    "            (\"drop2\", nn.Dropout(p=0))\n",
    "        ]))\n",
    "        self.y_embedding = nn.Parameter(torch.randn(max_length, in_features) / in_features ** 0.5)\n",
    "        # self.register_buffer(\"y_embedding\", nn.Parameter(torch.randn(120, in_features) / 10 ** 0.5))\n",
    "\n",
    "    # TODO: implement token dropout for classifier-free guidance\n",
    "    \n",
    "    def forward(self, x, train=False):\n",
    "        assert train == False, \"Token dropout is not implemented\"\n",
    "        return self.y_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaptionEmbedder(\n",
       "  (y_proj): Mlp(\n",
       "    (fc1): Linear(in_features=4096, out_features=768, bias=True)\n",
       "    (act): GELU(approximate='tanh')\n",
       "    (drop1): Dropout(p=0, inplace=False)\n",
       "    (norm): Identity()\n",
       "    (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (drop2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.y_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_caption_embedding(model):  \n",
    "    y_embedder = CaptionEmbeddingScratch(in_features=4096, hidden_features=768)\n",
    "    y_embedder.load_state_dict(model.y_embedder.state_dict())\n",
    "    with torch.no_grad():\n",
    "        tmp_state = torch.randn(5, 20, 4096)\n",
    "        assert torch.allclose(y_embedder(tmp_state), model.y_embedder(tmp_state, train=False))\n",
    "\n",
    "\n",
    "test_caption_embedding(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layers\n",
    "from xformers.ops import memory_efficient_attention\n",
    "import torch.nn.functional as F\n",
    "class AttentionScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_heads=12):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        self.qkv = nn.Linear(hidden_size, hidden_size * 3, bias=True)\n",
    "        self.attn_drop = nn.Dropout(0.0)\n",
    "        self.proj = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.proj_drop = nn.Dropout(0.0)\n",
    "\n",
    "    def forward(self, x, ):\n",
    "        B, N, C = x.shape\n",
    "        QKV = self.qkv(x)\n",
    "        QKV = QKV.reshape(B, N, 3, self.num_heads, self.head_dim)\n",
    "        # the F.scaled_dot_product_attention is not exactly the same as the memory_efficient_attention, but very close. \n",
    "        # Q, K, V = QKV.chunk(3, dim=-1) # (B, N, C)\n",
    "        # Q = rearrange(Q, \"b n (h d) -> (b h) n d\", h=self.num_heads)\n",
    "        # K = rearrange(K, \"b n (h d) -> (b h) n d\", h=self.num_heads)\n",
    "        # V = rearrange(V, \"b n (h d) -> (b h) n d\", h=self.num_heads)\n",
    "        # mha = F.scaled_dot_product_attention(Q, K, V, attn_mask=None, dropout_p=0.0, is_causal=False)\n",
    "        # mha = rearrange(mha, \"(b h) n d -> b n (h d)\", h=self.num_heads)\n",
    "        # Closer to the original implementation\n",
    "        Q, K, V = QKV.unbind(2)\n",
    "        mha = memory_efficient_attention(Q, K, V, p=0.0)\n",
    "        mha = mha.reshape(B, N, C)\n",
    "        return self.proj_drop(self.proj(mha))\n",
    "\n",
    "\n",
    "class CrossAttentionScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, encoder_hidden_size=768, num_heads=12, qkv_bias=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        self.cross_attn = nn.Identity()\n",
    "        self.q_linear = nn.Linear(hidden_size, hidden_size, bias=qkv_bias)\n",
    "        self.kv_linear = nn.Linear(encoder_hidden_size, hidden_size * 2, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(0.0)\n",
    "        self.proj = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.proj_drop = nn.Dropout(0.0)\n",
    "        \n",
    "    def forward(self, x, y, mask=None):\n",
    "        B, N, C = x.shape\n",
    "        # _, M, _ = y.shape\n",
    "        M = y.shape[-2]\n",
    "        Q = self.q_linear(x)\n",
    "        Q = Q.reshape(B, N, self.num_heads, self.head_dim)\n",
    "        K, V = self.kv_linear(y).reshape(B, -1, 2, self.num_heads, self.head_dim).unbind(2)\n",
    "        if mask is not None:\n",
    "            # assume mask is a boolean tensor of shape (B, 1, 1, M)\n",
    "            if mask.ndim == 2:\n",
    "                mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "            attn_bias = torch.zeros([B, self.num_heads, N, M], dtype=Q.dtype, device=Q.device)\n",
    "            attn_bias.masked_fill_(mask.repeat(1, self.num_heads, 1, 1) == 0, float('-inf'))\n",
    "            # attn_bias = torch.zeros([B * self.num_heads, q.shape[1], k.shape[1]], dtype=q.dtype, device=q.device)\n",
    "        else:\n",
    "            attn_bias = None\n",
    "        attn = memory_efficient_attention(Q, K, V, p=0.0, attn_bias=attn_bias)\n",
    "        attn = attn.reshape(B, N, C)\n",
    "        return self.proj_drop(self.proj(attn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2i_modulate(x, shift, scale):\n",
    "    return x * (1 + scale) + shift\n",
    "\n",
    "\n",
    "class TransformerBlockScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_heads=12, mlp_ratio=4.0, drop_path=0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.drop_path = drop_path\n",
    "        self.norm1 = nn.LayerNorm(768, elementwise_affine=False, eps=1e-6)\n",
    "        self.attn = AttentionScratch(hidden_size=hidden_size, num_heads=num_heads)\n",
    "        self.cross_attn = CrossAttentionScratch(hidden_size=hidden_size, encoder_hidden_size=hidden_size, num_heads=num_heads)\n",
    "        self.norm2 = nn.LayerNorm(768, elementwise_affine=False, eps=1e-6)\n",
    "        self.mlp = nn.Sequential(OrderedDict([\n",
    "            (\"fc1\", nn.Linear(hidden_size, int(hidden_size * mlp_ratio), bias=True)),\n",
    "            (\"act\", nn.GELU(approximate='tanh')),\n",
    "            (\"drop1\", nn.Dropout(p=0, inplace=False)),\n",
    "            (\"fc2\", nn.Linear(int(hidden_size * mlp_ratio), hidden_size, bias=True)),\n",
    "            (\"drop2\", nn.Dropout(p=0, inplace=False))\n",
    "        ]))\n",
    "        self.drop_path = nn.DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.scale_shift_table = nn.Parameter(torch.randn(6, hidden_size) / hidden_size ** 0.5)\n",
    "\n",
    "    def forward(self, x, y, t, mask=None, **kwargs):\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (self.scale_shift_table[None] + t.reshape(B, 6, -1)).chunk(6, dim=1)\n",
    "        x = x + self.drop_path(gate_msa * self.attn(t2i_modulate(self.norm1(x), shift_msa, scale_msa)).reshape(B, N, C))\n",
    "        x = x + self.cross_attn(x, y, mask)\n",
    "        x = x + self.drop_path(gate_mlp * self.mlp(t2i_modulate(self.norm2(x), shift_mlp, scale_mlp)))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PixArtBlock(\n",
       "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "  (attn): WindowAttention(\n",
       "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "    (q_norm): Identity()\n",
       "    (k_norm): Identity()\n",
       "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (cross_attn): MultiHeadCrossAttention(\n",
       "    (q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (kv_linear): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "  (mlp): Mlp(\n",
       "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (act): GELU(approximate='tanh')\n",
       "    (drop1): Dropout(p=0, inplace=False)\n",
       "    (norm): Identity()\n",
       "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (drop2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (drop_path): Identity()\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `WindowAttention` is not really used, window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowAttention(\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (q_norm): Identity()\n",
       "  (k_norm): Identity()\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadCrossAttention(\n",
       "  (q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (kv_linear): Linear(in_features=768, out_features=1536, bias=True)\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mlp(\n",
       "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (act): GELU(approximate='tanh')\n",
       "  (drop1): Dropout(p=0, inplace=False)\n",
       "  (norm): Identity()\n",
       "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (drop2): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check MLP output correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 768\n",
    "mlp_ratio = 4.0\n",
    "mlp = nn.Sequential(OrderedDict([\n",
    "    (\"fc1\", nn.Linear(hidden_size, int(hidden_size * mlp_ratio), bias=True)),\n",
    "    (\"act\", nn.GELU(approximate='tanh')),\n",
    "    (\"drop1\", nn.Dropout(p=0, inplace=False)),\n",
    "    (\"fc2\", nn.Linear(int(hidden_size * mlp_ratio), hidden_size, bias=True)),\n",
    "    (\"drop2\", nn.Dropout(p=0, inplace=False))\n",
    "]))\n",
    "mlp.load_state_dict(model.blocks[-1].mlp.state_dict())\n",
    "with torch.no_grad():\n",
    "    mlp.cuda()\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    mlp_out = mlp(tmp_state)\n",
    "    mlp_out_model = model.blocks[-1].mlp(tmp_state)\n",
    "    assert torch.allclose(mlp_out, mlp_out_model, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check attention output correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass of Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowAttention(\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (q_norm): Identity()\n",
       "  (k_norm): Identity()\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_src = AttentionScratch()\n",
    "attn_src.load_state_dict(model.blocks[-1].attn.state_dict())\n",
    "attn_src.cuda()\n",
    "with torch.no_grad():\n",
    "    model.cuda()\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    attn_output_src = attn_src(tmp_state)\n",
    "    attn_output_model = model.blocks[-1].attn(tmp_state) \n",
    "    assert torch.allclose(attn_output_src, attn_output_model, ), \"Self Attention output is not exactly the same\" # it's not exactly the same, but seems close enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attn_src = CrossAttentionScratch()\n",
    "cross_attn_src.load_state_dict(model.blocks[-1].cross_attn.state_dict())\n",
    "cross_attn_src.cuda()\n",
    "with torch.no_grad():\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    tmp_state_y = torch.randn(5, 20, 768).cuda()\n",
    "    attn_mask = None #torch.randint(0, 2, (5, 20)).cuda()\n",
    "    attn_output_src = cross_attn_src(tmp_state, tmp_state_y, mask=attn_mask)\n",
    "    attn_output_model = model.blocks[-1].cross_attn(tmp_state, tmp_state_y, mask=attn_mask) \n",
    "    assert torch.allclose(attn_output_src, attn_output_model, ), \"Cross Attention output is not exactly the same\" # it's not exactly the same, but seems close enough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = torch.zeros(5, 20).cuda().unsqueeze(1).unsqueeze(1)\n",
    "# y = y.squeeze(1).masked_select(attn_mask.unsqueeze(-1) != 0).view(1, -1, x.shape[-1])\n",
    "y_lens = attn_mask.sum(dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 2\n",
    "cross_attn_src = CrossAttentionScratch()\n",
    "cross_attn_src.load_state_dict(model.blocks[block_idx].cross_attn.state_dict())\n",
    "cross_attn_src.cuda()\n",
    "with torch.no_grad():\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    tmp_state_y = torch.randn(5, 20, 768).cuda()\n",
    "    attn_mask = torch.zeros(5, 20, dtype=torch.bool).cuda()\n",
    "    attn_mask[:, 0:1] = True\n",
    "    attn_mask[2, 0:4] = True\n",
    "    attn_mask[3, 0:3] = True\n",
    "    # attn_mask = attn_mask.unsqueeze(1).unsqueeze(1)\n",
    "    y_lens = attn_mask.squeeze(1).squeeze(1).sum(dim=1).tolist()\n",
    "    attn_output_src = cross_attn_src(tmp_state, tmp_state_y, mask=attn_mask)\n",
    "    attn_output_model = model.blocks[block_idx].cross_attn(tmp_state, tmp_state_y, mask=y_lens) \n",
    "    assert torch.allclose(attn_output_src, attn_output_model, ) # it's not exactly the same, but seems close enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 4, 3, 1]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xformers\n",
    "attn_bias = xformers.ops.fmha.BlockDiagonalMask.from_seqlens([64] * 5, y_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockDiagonalMask(q_seqinfo=_SeqLenInfo(seqstart=tensor([  0,  64, 128, 192, 256, 320], dtype=torch.int32), max_seqlen=64, min_seqlen=64, seqstart_py=[0, 64, 128, 192, 256, 320]), k_seqinfo=_SeqLenInfo(seqstart=tensor([ 0,  1,  2,  6,  9, 10], dtype=torch.int32), max_seqlen=4, min_seqlen=1, seqstart_py=[0, 1, 2, 6, 9, 10]), _batch_sizes=None)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "block_idx = 1\n",
    "block_src = TransformerBlockScratch().cuda()\n",
    "block_src.load_state_dict(model.blocks[block_idx].state_dict())\n",
    "assert torch.allclose(block_src.scale_shift_table, model.blocks[block_idx].scale_shift_table)\n",
    "with torch.no_grad():\n",
    "    block_src.eval()\n",
    "    model.eval()\n",
    "    tmp_state = torch.randn(7, 64, 768).cuda()\n",
    "    tmp_state_y = torch.randn(7, 20, 768).cuda()\n",
    "    tmp_t = torch.randn(7, 768 * 6).cuda()\n",
    "    attn_mask = torch.zeros(7, 20, dtype=torch.bool).cuda().unsqueeze(1).unsqueeze(1)\n",
    "    attn_mask[:, :, :, 0:1] = True\n",
    "    attn_mask[2, :, :, 0:4] = True\n",
    "    attn_mask[4, :, :, 0:4] = True\n",
    "    y_lens = attn_mask.squeeze(1).squeeze(1).sum(dim=1).tolist()\n",
    "    src_out = block_src(tmp_state, tmp_state_y, tmp_t, mask=attn_mask)\n",
    "    model_out = model.blocks[block_idx](tmp_state, tmp_state_y, tmp_t, mask=y_lens)\n",
    "    assert torch.allclose(src_out, model_out, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking gating parameters correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_tmp = torch.randn(7, 64, 768).cuda()\n",
    "torch.allclose(model.blocks[block_idx].attn(state_tmp), block_src.attn(state_tmp))\n",
    "# model.blocks[block_idx].attn(state_tmp)\n",
    "# block_src.attn(state_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_msa_src, scale_msa_src, gate_msa_src, shift_mlp_src, scale_mlp_src, gate_mlp_src = (block_src.scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    "shift_msa_model, scale_msa_model, gate_msa_model, shift_mlp_model, scale_mlp_model, gate_mlp_model = (model.blocks[block_idx].scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    " \n",
    "state_src = (t2i_modulate(block_src.norm1(tmp_state), shift_msa_src, scale_msa_src))\n",
    "state_model = (t2i_modulate(model.blocks[block_idx].norm1(tmp_state), shift_msa_model, scale_msa_model))\n",
    "# this is true, \n",
    "# this is not true, the attention is not the same\n",
    "# state_src = block_src.attn(t2i_modulate(block_src.norm1(tmp_state), shift_msa_src, scale_msa_src))\n",
    "# state_model = model.blocks[block_idx].attn(t2i_modulate(model.blocks[block_idx].norm1(tmp_state), shift_msa_model, scale_msa_model))\n",
    "torch.allclose(state_src, state_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_params_src = (block_src.scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    "gating_params_model = (model.blocks[block_idx].scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    "assert all(torch.allclose(gating_params_src, gating_params_model) for gating_params_src, gating_params_model in zip(gating_params_src, gating_params_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 64, 768]), torch.Size([7, 64, 768]))"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_out.shape, model_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final readout layer \n",
    "class FinalLayerScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, out_channel=32):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.norm_final = nn.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6)\n",
    "        self.linear = nn.Linear(hidden_size, out_channel, bias=True)\n",
    "        self.scale_shift_table = nn.Parameter(torch.randn(2, hidden_size) / hidden_size ** 0.5)\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        shift, scale = (self.scale_shift_table[None] + t_emb[:, None]).chunk(2, dim=1)\n",
    "        x = t2i_modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def unpatchify(x, patch_size=2):\n",
    "    B, T, C = x.shape\n",
    "    H = W = int(T ** 0.5)\n",
    "    assert H * W == T\n",
    "    x = rearrange(x, \"b (h w) (p1 p2 c) -> b c (h p1) (w p2)\", \n",
    "                    h=H, w=W, p1=patch_size, p2=patch_size)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T2IFinalLayer(\n",
       "  (norm_final): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "  (linear): Linear(in_features=768, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.final_layer.scale_shift_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "final_layer_src = FinalLayerScratch().cuda()\n",
    "final_layer_src.load_state_dict(model.final_layer.state_dict())\n",
    "with torch.no_grad():\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    tmp_t = torch.randn(5, 768).cuda()\n",
    "    final_out_src = final_layer_src(tmp_state, tmp_t)\n",
    "    final_out_model = model.final_layer(tmp_state, tmp_t)\n",
    "    assert torch.allclose(final_out_src, final_out_model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hidden_tmp = torch.randn(5, 64, 32)\n",
    "assert torch.allclose(unpatchify(hidden_tmp), model.unpatchify(hidden_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass(model, batch_size=7, device=\"cuda\"):\n",
    "    model.eval().to(device)\n",
    "    # Define the modules from scratch\n",
    "    patch_size = 2\n",
    "    hidden_size = 768\n",
    "    num_heads = 12\n",
    "    in_channels = 4\n",
    "    out_channels = in_channels * 2\n",
    "    mlp_ratio = 4.0\n",
    "    drop_path = 0.0\n",
    "    pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "    pos_embed = torch.from_numpy(pos_embed).unsqueeze(0).to(torch.float32).to(device)\n",
    "    x_embedder = PatchEmbeddingScratch(in_channels=in_channels, out_channels=hidden_size, patch_size=patch_size)\n",
    "    t_embedder = TimeEmbeddingScratch(hidden_size, freq_embedding_size=256)\n",
    "    t_blocks = get_time_blocks(hidden_size)\n",
    "    y_embedder = CaptionEmbeddingScratch(in_features=4096, hidden_features=hidden_size)\n",
    "    final_layer = FinalLayerScratch(hidden_size=hidden_size, out_channel=out_channels * patch_size * patch_size)\n",
    "\n",
    "    x_embedder.load_state_dict(model.x_embedder.state_dict())\n",
    "    t_embedder.load_state_dict(model.t_embedder.state_dict())\n",
    "    t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "    y_embedder.load_state_dict(model.y_embedder.state_dict())\n",
    "    final_layer.load_state_dict(model.final_layer.state_dict())\n",
    "\n",
    "    transformer_blocks = nn.ModuleList([TransformerBlockScratch(hidden_size=hidden_size, num_heads=num_heads, mlp_ratio=mlp_ratio, drop_path=drop_path) for _ in range(12)])\n",
    "    transformer_blocks.load_state_dict(model.blocks.state_dict())\n",
    "    for module in [x_embedder, t_embedder, t_blocks, y_embedder, final_layer, transformer_blocks]:\n",
    "        module.eval()\n",
    "        module.requires_grad = False\n",
    "        module.to(device)\n",
    "\n",
    "    # Generate psuedo input\n",
    "    x_tmp = torch.randn(batch_size, 4, 16, 16).to(device)\n",
    "    t_tmp = torch.randint(0, 1000, (batch_size,)).to(device)\n",
    "    y_tmp = torch.randn(batch_size, 20, 4096).to(device)\n",
    "    attn_mask = torch.zeros(batch_size, 20, dtype=torch.bool).to(device)\n",
    "    attn_mask[:, 0:1] = True\n",
    "    attn_mask[2, 0:4] = True\n",
    "    attn_mask[4, 0:4] = True\n",
    "    \n",
    "    # Forward pass \n",
    "    x_embed = x_embedder(x_tmp) # (B, T, D)\n",
    "    x_embed = x_embed + pos_embed # (B, T, D)\n",
    "    t_embed = t_embedder(t_tmp) # (B, D)\n",
    "    t_blocks_out = t_blocks(t_embed) # (B, D * 6)\n",
    "    y_embed = y_embedder(y_tmp, train=False) # (B, 1, L, D)\n",
    "    print(\"X input shape:\", x_tmp.shape)\n",
    "    print(\"Pos embed shape:\", pos_embed.shape)\n",
    "    print(\"T embed shape:\", t_embed.shape)\n",
    "    print(\"T blocks out shape:\", t_blocks_out.shape)\n",
    "    print(\"Y embed shape:\", y_embed.shape)\n",
    "\n",
    "    # go through the transformer blocks\n",
    "    for block in transformer_blocks:\n",
    "        x_embed = block(x_embed, y_embed, t_blocks_out, mask=attn_mask)\n",
    "\n",
    "    final_out = final_layer(x_embed, t_embed)\n",
    "    final_out = unpatchify(final_out)\n",
    "    \n",
    "    # compare with the model\n",
    "    final_out_model = model.forward(x_tmp, t_tmp, y_tmp, mask=attn_mask)\n",
    "    assert torch.allclose(final_out, final_out_model, )\n",
    "    return final_out, final_out_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "x_embedder = PatchEmbeddingScratch(in_channels=4, out_channels=768, patch_size=2)\n",
    "t_embedder = TimeEmbeddingScratch(768, freq_embedding_size=256)\n",
    "t_blocks = get_time_blocks(768)\n",
    "y_embedder = CaptionEmbeddingScratch(in_features=4096, hidden_features=768)\n",
    "final_layer = FinalLayerScratch(hidden_size=768, out_channel=32)\n",
    "\n",
    "x_embedder.load_state_dict(model.x_embedder.state_dict())\n",
    "t_embedder.load_state_dict(model.t_embedder.state_dict())\n",
    "t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "y_embedder.load_state_dict(model.y_embedder.state_dict())\n",
    "final_layer.load_state_dict(model.final_layer.state_dict())\n",
    "\n",
    "transformer_blocks = nn.ModuleList([TransformerBlockScratch().cuda() for _ in range(12)])\n",
    "transformer_blocks.load_state_dict(model.blocks.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "for module in [x_embedder, t_embedder, t_blocks, y_embedder, final_layer, transformer_blocks]:\n",
    "    module.eval()\n",
    "    module.requires_grad = False\n",
    "    module.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X input shape: torch.Size([5, 4, 16, 16])\n",
      "Pos embed shape: torch.Size([1, 64, 768])\n",
      "T embed shape: torch.Size([5, 768])\n",
      "T blocks out shape: torch.Size([5, 4608])\n",
      "Y embed shape: torch.Size([5, 20, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8, 16, 16])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass \n",
    "x_tmp = torch.randn(5, 4, 16, 16).to(device)\n",
    "t_tmp = torch.randint(0, 1000, (5,)).to(device)\n",
    "y_tmp = torch.randn(5, 20, 4096).to(device)\n",
    "pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "pos_embed = torch.tensor(pos_embed).unsqueeze(0).to(torch.float32).to(device)\n",
    "attn_mask = torch.zeros(5, 20, dtype=torch.bool).to(device)\n",
    "attn_mask[:, 0:1] = True\n",
    "attn_mask[2, 0:4] = True\n",
    "attn_mask[4, 0:4] = True\n",
    "\n",
    "x_embed = x_embedder(x_tmp) # (B, T, D)\n",
    "x_embed = x_embed + pos_embed # (B, T, D)\n",
    "t_embed = t_embedder(t_tmp) # (B, D)\n",
    "t_blocks_out = t_blocks(t_embed) # (B, D * 6)\n",
    "y_embed = y_embedder(y_tmp, train=False) # (B, 1, L, D)\n",
    "print(\"X input shape:\", x_tmp.shape)\n",
    "print(\"Pos embed shape:\", pos_embed.shape)\n",
    "print(\"T embed shape:\", t_embed.shape)\n",
    "print(\"T blocks out shape:\", t_blocks_out.shape)\n",
    "print(\"Y embed shape:\", y_embed.shape)\n",
    "\n",
    "# go through the transformer blocks\n",
    "for block in transformer_blocks:\n",
    "    x_embed = block(x_embed, y_embed, t_blocks_out, mask=attn_mask)\n",
    "\n",
    "final_out = final_layer(x_embed, t_embed)\n",
    "final_out = unpatchify(final_out)\n",
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "final_out_model = model.forward(x_tmp, t_tmp, y_tmp, mask=attn_mask)\n",
    "assert torch.allclose(final_out, final_out_model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
