{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b24dcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/xformers/ops/swiglu_op.py:128: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(cls, ctx, x, w1, b1, w2, b2, w3, b3):\n",
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/xformers/ops/swiglu_op.py:149: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(cls, ctx, dx5):\n",
      "/n/home12/binxuwang/.conda/envs/torch2/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2025-07-30 22:57:46,218 - PixArt - INFO - Constructing dataset InternalData...\n",
      "2025-07-30 22:57:46,265 - PixArt - INFO - T5 max token length: 20\n",
      "2025-07-30 22:57:46,266 - PixArt - INFO - Dataset InternalData constructed. time: 0.05 s, length (use/ori): 10000/10000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/DiffusionObjectRelation/PixArt-alpha\")\n",
    "from diffusion.data.builder import build_dataset, build_dataloader, set_data_root\n",
    "\n",
    "\n",
    "data = dict(type='InternalData', root='/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/PixArt/training_datasets/objectRelDouble_pilot1_RndEmb', \n",
    "            image_list_json=['data_info.json',], transform='default_train', load_vae_feat=True, max_length=20)\n",
    "\n",
    "dataset = build_dataset(\n",
    "        data, resolution=128, aspect_ratio_type=None,\n",
    "        real_prompt_ratio=0.5, max_length=20, config=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1d1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 22:49:24,399 - PixArt - INFO - Constructing dataset InternalData...\n",
      "2025-07-30 22:49:24,445 - PixArt - INFO - T5 max token length: 20\n",
      "2025-07-30 22:49:24,446 - PixArt - INFO - Dataset InternalData constructed. time: 0.05 s, length (use/ori): 10000/10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = dict(type='InternalData', root='/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/PixArt/training_datasets/objectRelDouble_pilot1_RndEmb', \n",
    "            image_list_json=['data_info.json',], transform='default_train', load_vae_feat=True, max_length=20)\n",
    "\n",
    "dataset = build_dataset(\n",
    "        data, resolution=128, aspect_ratio_type=None,\n",
    "        real_prompt_ratio=0.5, max_length=20, config=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f44ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def __getitem__(self, idx):\n",
      "        for _ in range(20):\n",
      "            try:\n",
      "                return self.getdata(idx)\n",
      "            except Exception as e:\n",
      "                print(f\"Error details: {str(e)}\")\n",
      "                idx = np.random.randint(len(self))\n",
      "        raise RuntimeError('Too many bad data.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(dataset.__getitem__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db50709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def getdata(self, index):\n",
      "        img_path = self.img_samples[index]\n",
      "        npz_path = self.txt_feat_samples[index]\n",
      "        npy_path = self.vae_feat_samples[index]\n",
      "        prompt = self.prompt_samples[index]\n",
      "        data_info = {\n",
      "            'img_hw': torch.tensor([torch.tensor(self.resolution), torch.tensor(self.resolution)], dtype=torch.float32),\n",
      "            'aspect_ratio': torch.tensor(1.)\n",
      "        }\n",
      "\n",
      "        img = self.loader(npy_path) if self.load_vae_feat else self.loader(img_path)\n",
      "        txt_info = np.load(npz_path)\n",
      "        txt_fea = torch.from_numpy(txt_info['caption_feature'])     # 1xTx4096\n",
      "        attention_mask = torch.ones(1, 1, txt_fea.shape[1])     # 1x1xT\n",
      "        if 'attention_mask' in txt_info.keys():\n",
      "            attention_mask = torch.from_numpy(txt_info['attention_mask'])[None]\n",
      "        if txt_fea.shape[1] != self.max_lenth:\n",
      "            txt_fea = torch.cat([txt_fea, txt_fea[:, -1:].repeat(1, self.max_lenth-txt_fea.shape[1], 1)], dim=1)\n",
      "            attention_mask = torch.cat([attention_mask, torch.zeros(1, 1, self.max_lenth-attention_mask.shape[-1])], dim=-1)\n",
      "\n",
      "        if self.transform:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        data_info['prompt'] = prompt\n",
      "        return img, txt_fea, attention_mask, data_info\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(dataset.getdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29efa0cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to create tensor with negative dimension -81520: [1, -81520, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetdata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/DiffusionObjectRelation/PixArt-alpha/diffusion/data/datasets/InternalData.py:88\u001b[0m, in \u001b[0;36mInternalData.getdata\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     86\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(txt_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m txt_fea\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_lenth:\n\u001b[0;32m---> 88\u001b[0m     txt_fea \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([txt_fea, \u001b[43mtxt_fea\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_lenth\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtxt_fea\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     89\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([attention_mask, torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_lenth\u001b[38;5;241m-\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to create tensor with negative dimension -81520: [1, -81520, 1]"
     ]
    }
   ],
   "source": [
    "dataset.getdata(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd33c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.max_lenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90995d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
