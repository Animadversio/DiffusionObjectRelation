{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "\n",
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, num_images, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - num_images: Integer specifying the number of images in the dataset.\n",
    "        - transform: Optional torchvision transforms to apply to the images.\n",
    "        \"\"\"\n",
    "        self.num_images = num_images\n",
    "        self.shapes = ['triangle', 'circle', 'square']\n",
    "        self.canvas_size = 64\n",
    "        self.transform = transform\n",
    "        self.shape_to_idx = {'triangle': 0, 'circle': 1, 'square': 2}\n",
    "        self.radius = 8\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def draw_shape_on_image(self, img, shape, location, color='black'):\n",
    "        \"\"\"\n",
    "        Draws a specified shape at a given location on the provided image.\n",
    "\n",
    "        Parameters:\n",
    "        - img: PIL Image object to draw on.\n",
    "        - shape: String specifying the shape ('triangle', 'circle', 'square').\n",
    "        - location: Tuple (x, y) specifying the location of the shape's center.\n",
    "\n",
    "        Returns:\n",
    "        - img: PIL Image object with the shape drawn on it.\n",
    "        \"\"\"\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        x, y = location\n",
    "\n",
    "        if shape == 'circle':\n",
    "            r = self.radius  # Radius\n",
    "            leftUpPoint = (x - r, y - r)\n",
    "            rightDownPoint = (x + r, y + r)\n",
    "            draw.ellipse([leftUpPoint, rightDownPoint], fill=color)\n",
    "\n",
    "        elif shape == 'square':\n",
    "            s = self.radius * 2  # Side length\n",
    "            leftUpPoint = (x - s // 2, y - s // 2)\n",
    "            rightDownPoint = (x + s // 2, y + s // 2)\n",
    "            draw.rectangle([leftUpPoint, rightDownPoint], fill=color)\n",
    "\n",
    "        elif shape == 'triangle':\n",
    "            s = self.radius * 2  # Side length\n",
    "            h = s * (3 ** 0.5) / 2  # Height of the equilateral triangle\n",
    "            point1 = (x, y - h / 3)\n",
    "            point2 = (x - s / 2, y + h * 2 / 3)\n",
    "            point3 = (x + s / 2, y + h * 2 / 3)\n",
    "            draw.polygon([point1, point2, point3], fill=color)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Shape must be 'triangle', 'circle', or 'square'.\")\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one image and its labels.\n",
    "\n",
    "        Parameters:\n",
    "        - idx: Index of the image (not used as images are generated on-the-fly).\n",
    "\n",
    "        Returns:\n",
    "        - img: Tensor representing the image.\n",
    "        - labels: Dictionary containing the shapes and locations of the objects.\n",
    "        \"\"\"\n",
    "        # Create a blank image\n",
    "        img = Image.new('RGB', (self.canvas_size, self.canvas_size), 'gray')\n",
    "\n",
    "        # Randomly select two shapes, make sure they are different\n",
    "        shape1 = random.choice(self.shapes)\n",
    "        while True:\n",
    "            shape2 = random.choice(self.shapes)\n",
    "            if shape1 != shape2:\n",
    "                break\n",
    "\n",
    "        # Randomly select locations\n",
    "        x1 = random.randint(self.radius + 1, self.canvas_size - self.radius - 1)\n",
    "        y1 = random.randint(self.radius + 1, self.canvas_size - self.radius - 1)\n",
    "        x2 = random.randint(self.radius + 1, self.canvas_size - self.radius - 1)\n",
    "        y2 = random.randint(self.radius + 1, self.canvas_size - self.radius - 1)\n",
    "\n",
    "        # Randomly decide drawing order to allow overlapping\n",
    "        if random.random() < 0.5:\n",
    "            img = self.draw_shape_on_image(img, shape1, (x1, y1), color=\"red\")\n",
    "            img = self.draw_shape_on_image(img, shape2, (x2, y2), color=\"blue\")\n",
    "            shapes_order = [shape1, shape2]\n",
    "            locations_order = [(x1, y1), (x2, y2)]\n",
    "        else:\n",
    "            img = self.draw_shape_on_image(img, shape2, (x2, y2), color=\"blue\")\n",
    "            img = self.draw_shape_on_image(img, shape1, (x1, y1), color=\"red\")\n",
    "            shapes_order = [shape2, shape1]\n",
    "            locations_order = [(x2, y2), (x1, y1)]\n",
    "\n",
    "        # Apply transforms if any\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "\n",
    "        # Encode labels\n",
    "        labels = {\n",
    "            'shape1': self.shape_to_idx[shapes_order[0]],\n",
    "            'location1': torch.tensor(locations_order[0], dtype=torch.float32),\n",
    "            'shape2': self.shape_to_idx[shapes_order[1]],\n",
    "            'location2': torch.tensor(locations_order[1], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "        return img, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([16, 3, 64, 64])\n",
      "Labels batch: {'shape1': tensor([2, 1, 0, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0]), 'location1': tensor([[27., 20.],\n",
      "        [50., 44.],\n",
      "        [53., 16.],\n",
      "        [48., 21.],\n",
      "        [35., 44.],\n",
      "        [35., 28.],\n",
      "        [12., 54.],\n",
      "        [40., 25.],\n",
      "        [14., 21.],\n",
      "        [51., 47.],\n",
      "        [54., 35.],\n",
      "        [53., 13.],\n",
      "        [25., 44.],\n",
      "        [50., 55.],\n",
      "        [26., 50.],\n",
      "        [52., 24.]]), 'shape2': tensor([0, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 2, 1, 1, 0, 2]), 'location2': tensor([[16., 52.],\n",
      "        [51., 10.],\n",
      "        [34., 45.],\n",
      "        [32., 40.],\n",
      "        [26., 47.],\n",
      "        [43., 23.],\n",
      "        [32., 48.],\n",
      "        [32., 34.],\n",
      "        [10., 29.],\n",
      "        [42., 45.],\n",
      "        [45., 55.],\n",
      "        [39., 25.],\n",
      "        [13., 40.],\n",
      "        [51., 55.],\n",
      "        [29., 20.],\n",
      "        [12., 36.]])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "if __name__ == '__main__':\n",
    "    # Define any transforms (optional)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # Add more transforms if needed\n",
    "    ])\n",
    "    # Create the dataset\n",
    "    dataset = ShapesDataset(num_images=1000, transform=transform)\n",
    "    # Create a DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    # Iterate over the DataLoader\n",
    "    for images, labels in dataloader:\n",
    "        print(f\"Images batch shape: {images.size()}\")\n",
    "        print(f\"Labels batch: {labels}\")\n",
    "        break  # Just process one batch for demonstration\n",
    "\n",
    "    # Display one image and its labels (optional)\n",
    "    import matplotlib.pyplot as plt\n",
    "    img, lbl = dataset[0]\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(img_np)\n",
    "    shape_names = {0: 'triangle', 1: 'circle', 2: 'square'}\n",
    "    plt.title(f\"Shapes: {shape_names[lbl['shape1']]} at {tuple(lbl['location1'].numpy())}, \"\n",
    "              f\"{shape_names[lbl['shape2']]} at {tuple(lbl['location2'].numpy())}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4849)\n",
      "tensor(0.1583)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Add more transforms if needed\n",
    "])\n",
    "# Create the dataset\n",
    "dataset = ShapesDataset(num_images=10000, transform=transform)\n",
    "# sample 10000 images and save the images and labels as tensors\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(10000):\n",
    "    img, lbl = dataset[i]\n",
    "    images.append(img)\n",
    "    labels.append(lbl)\n",
    "    \n",
    "image_tensors = torch.stack(images)\n",
    "print(image_tensors.mean())\n",
    "print(image_tensors.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1 = torch.tensor([item['shape1'] for item in labels], dtype=torch.long)\n",
    "location1 = torch.stack([item['location1'] for item in labels], dim=0)\n",
    "shape2 = torch.tensor([item['shape2'] for item in labels], dtype=torch.long)\n",
    "location2 = torch.stack([item['location2'] for item in labels], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "dataset = TensorDataset(image_tensors, shape1, location1, shape2, location2)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/Diffusion_ObjectRelation': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/Diffusion_ObjectRelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/Diffusion_ObjectRelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "savedir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/Diffusion_ObjectRelation\"\n",
    "os.makedirs(join(savedir, \"dataset\"), exist_ok=True)\n",
    "torch.save({\"images\": image_tensors, \"shape1\": shape1, \"location1\": location1, \"shape2\": shape2, \"location2\": location2}, \n",
    "           join(savedir, \"dataset\", \"shapes_dataset_pilot.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDatasetCached(Dataset):\n",
    "    filename = \"shapes_dataset_pilot.pth\"\n",
    "    savedir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/Diffusion_ObjectRelation\"\n",
    "    def __init__(self, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - transform: Optional torchvision transforms to apply to the images.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.data = torch.load(join(self.savedir, \"dataset\", self.filename))\n",
    "        self.images = self.data[\"images\"]\n",
    "        self.shape1 = self.data[\"shape1\"]\n",
    "        self.location1 = self.data[\"location1\"]\n",
    "        self.shape2 = self.data[\"shape2\"]\n",
    "        self.location2 = self.data[\"location2\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        shape1 = self.shape1[idx]\n",
    "        location1 = self.location1[idx]\n",
    "        shape2 = self.shape2[idx]\n",
    "        location2 = self.location2[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, (shape1, location1, shape2, location2)\n",
    "    \n",
    "dataset2 = ShapesDatasetCached(transform=transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         ...,\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]],\n",
       "\n",
       "        [[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         ...,\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]],\n",
       "\n",
       "        [[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         ...,\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 64, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensors.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
