{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/hf/misc\n"
     ]
    }
   ],
   "source": [
    "!echo $HF_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/hjkim/.conda/envs/torch2/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/n/home12/hjkim/.conda/envs/torch2/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/n/home12/hjkim/.conda/envs/torch2/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "from diffusers import AutoencoderKL, Transformer2DModel, PixArtAlphaPipeline, DPMSolverMultistepScheduler\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/hjkim/Github/DiffusionObjectRelation/PixArt-alpha\")\n",
    "\n",
    "from diffusion import IDDPM\n",
    "from diffusion.data.builder import build_dataset, build_dataloader, set_data_root\n",
    "from diffusion.model.builder import build_model\n",
    "from diffusion.utils.misc import set_random_seed, read_config, init_random_seed, DebugUnderflowOverflow\n",
    "sys.path.append(\"/n/home12/hjkim/Github/DiffusionObjectRelation/utils\")\n",
    "from pixart_utils import state_dict_convert\n",
    "from image_utils import pil_images_to_grid\n",
    "from pixart_utils import state_dict_convert\n",
    "from pixart_sampling_utils import PixArtAlphaPipeline_custom, visualize_prompts_with_traj\n",
    "from pixart_utils import construct_diffuser_transformer_from_config, construct_diffuser_pipeline_from_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 10:37:00,453 - PixArt - WARNING - lewei scale: (1.0,), base size: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce244791e7024c0898d993a059d0ad32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected types for transformer: (<class 'diffusers.models.transformers.pixart_transformer_2d.PixArtTransformer2DModel'>,), got <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>.\n"
     ]
    }
   ],
   "source": [
    "savedir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/PixArt/results/objrel_rndembdposemb_DiT_B_pilot\"\n",
    "\n",
    "config = read_config(join(savedir, 'config.py'))\n",
    "\n",
    "weight_dtype = torch.float32\n",
    "if config.mixed_precision == \"fp16\": # accelerator.\n",
    "    weight_dtype = torch.float16\n",
    "elif config.mixed_precision == \"bf16\": # accelerator.\n",
    "    weight_dtype = torch.bfloat16\n",
    "    \n",
    "image_size = config.image_size  # @param [256, 512, 1024]\n",
    "latent_size = int(image_size) // 8\n",
    "pred_sigma = getattr(config, 'pred_sigma', True)\n",
    "learn_sigma = getattr(config, 'learn_sigma', True) and pred_sigma\n",
    "model_kwargs={\"window_block_indexes\": config.window_block_indexes, \"window_size\": config.window_size,\n",
    "                \"use_rel_pos\": config.use_rel_pos, \"lewei_scale\": config.lewei_scale, 'config':config,\n",
    "                'model_max_length': config.model_max_length}\n",
    "# train_diffusion = IDDPM(str(config.train_sampling_steps), learn_sigma=learn_sigma, pred_sigma=pred_sigma, snr=config.snr_loss)\n",
    "model = build_model(config.model,\n",
    "                config.grad_checkpointing,\n",
    "                config.get('fp32_attention', False),\n",
    "                input_size=latent_size,\n",
    "                learn_sigma=learn_sigma,\n",
    "                pred_sigma=pred_sigma,\n",
    "                **model_kwargs).train()\n",
    "\n",
    "transformer = Transformer2DModel(\n",
    "        sample_size=image_size // 8,\n",
    "        num_layers=len(model.blocks),\n",
    "        attention_head_dim=model.blocks[0].hidden_size // model.num_heads,\n",
    "        in_channels=model.in_channels,\n",
    "        out_channels=model.out_channels,\n",
    "        patch_size=model.patch_size,\n",
    "        attention_bias=True,\n",
    "        num_attention_heads=model.num_heads,\n",
    "        cross_attention_dim=model.blocks[0].hidden_size,\n",
    "        activation_fn=\"gelu-approximate\",\n",
    "        num_embeds_ada_norm=1000,\n",
    "        norm_type=\"ada_norm_single\",\n",
    "        norm_elementwise_affine=False,\n",
    "        norm_eps=1e-6,\n",
    "        caption_channels=4096,\n",
    ")\n",
    "# state_dict = state_dict_convert(all_state_dict.pop(\"state_dict\"))\n",
    "transformer.load_state_dict(state_dict_convert(model.state_dict()))\n",
    "pipeline = PixArtAlphaPipeline_custom.from_pretrained(\n",
    "    \"PixArt-alpha/PixArt-XL-2-512x512\",\n",
    "    transformer=transformer,\n",
    "    tokenizer=None,\n",
    "    text_encoder=None,\n",
    "    torch_dtype=weight_dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3136395/1495998778.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(join(ckptdir, \"epoch_4000_step_160000.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckptdir = join(savedir, \"checkpoints\")\n",
    "ckpt = torch.load(join(ckptdir, \"epoch_4000_step_160000.pth\"))\n",
    "pipeline.transformer.load_state_dict(state_dict_convert(ckpt['state_dict_ema']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PixArt(\n",
       "  (x_embedder): PatchEmbed(\n",
       "    (proj): Conv2d(4, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (t_block): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=768, out_features=4608, bias=True)\n",
       "  )\n",
       "  (y_embedder): CaptionEmbedder(\n",
       "    (y_proj): Mlp(\n",
       "      (fc1): Linear(in_features=4096, out_features=768, bias=True)\n",
       "      (act): GELU(approximate='tanh')\n",
       "      (drop1): Dropout(p=0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x PixArtBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): WindowAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (cross_attn): MultiHeadCrossAttention(\n",
       "        (q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (kv_linear): Linear(in_features=768, out_features=1536, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='tanh')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "    )\n",
       "  )\n",
       "  (final_layer): T2IFinalLayer(\n",
       "    (norm_final): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=768, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 10:42:37,600 - PixArt - WARNING - lewei scale: (1.0,), base size: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903aa2916733406fa1930a58424335e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected types for transformer: (<class 'diffusers.models.transformers.pixart_transformer_2d.PixArtTransformer2DModel'>,), got <class 'diffusers.models.transformers.transformer_2d.Transformer2DModel'>.\n",
      "/tmp/ipykernel_3136395/4255857047.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(join(ckptdir, \"epoch_4000_step_160000.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/PixArt/results/objrel_rndembdposemb_DiT_B_pilot\"\n",
    "\n",
    "\n",
    "config = read_config(join(savedir, 'config.py'))\n",
    "\n",
    "weight_dtype = torch.float32\n",
    "if config.mixed_precision == \"fp16\": # accelerator.\n",
    "    weight_dtype = torch.float16\n",
    "elif config.mixed_precision == \"bf16\": # accelerator.\n",
    "    weight_dtype = torch.bfloat16\n",
    "    \n",
    "image_size = config.image_size  # @param [256, 512, 1024]\n",
    "latent_size = int(image_size) // 8\n",
    "pred_sigma = getattr(config, 'pred_sigma', True)\n",
    "learn_sigma = getattr(config, 'learn_sigma', True) and pred_sigma\n",
    "model_kwargs={\"window_block_indexes\": config.window_block_indexes, \"window_size\": config.window_size,\n",
    "                \"use_rel_pos\": config.use_rel_pos, \"lewei_scale\": config.lewei_scale, 'config':config,\n",
    "                'model_max_length': config.model_max_length}\n",
    "# train_diffusion = IDDPM(str(config.train_sampling_steps), learn_sigma=learn_sigma, pred_sigma=pred_sigma, snr=config.snr_loss)\n",
    "model = build_model(config.model,\n",
    "                config.grad_checkpointing,\n",
    "                config.get('fp32_attention', False),\n",
    "                input_size=latent_size,\n",
    "                learn_sigma=learn_sigma,\n",
    "                pred_sigma=pred_sigma,\n",
    "                **model_kwargs).train()\n",
    "\n",
    "transformer = Transformer2DModel(\n",
    "        sample_size=image_size // 8,\n",
    "        num_layers=len(model.blocks),\n",
    "        attention_head_dim=model.blocks[0].hidden_size // model.num_heads,\n",
    "        in_channels=model.in_channels,\n",
    "        out_channels=model.out_channels,\n",
    "        patch_size=model.patch_size,\n",
    "        attention_bias=True,\n",
    "        num_attention_heads=model.num_heads,\n",
    "        cross_attention_dim=model.blocks[0].hidden_size,\n",
    "        activation_fn=\"gelu-approximate\",\n",
    "        num_embeds_ada_norm=1000,\n",
    "        norm_type=\"ada_norm_single\",\n",
    "        norm_elementwise_affine=False,\n",
    "        norm_eps=1e-6,\n",
    "        caption_channels=4096,\n",
    ")\n",
    "# state_dict = state_dict_convert(all_state_dict.pop(\"state_dict\"))\n",
    "transformer.load_state_dict(state_dict_convert(model.state_dict()))\n",
    "pipeline = PixArtAlphaPipeline_custom.from_pretrained(\n",
    "    \"PixArt-alpha/PixArt-XL-2-512x512\",\n",
    "    transformer=transformer,\n",
    "    tokenizer=None,\n",
    "    text_encoder=None,\n",
    "    torch_dtype=weight_dtype,\n",
    ")\n",
    "ckptdir = join(savedir, \"checkpoints\")\n",
    "ckpt = torch.load(join(ckptdir, \"epoch_4000_step_160000.pth\"))\n",
    "pipeline.transformer.load_state_dict(state_dict_convert(ckpt['state_dict_ema'])) # model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/hjkim/Github/DiffusionObjectRelation/utils/pixart_sampling_utils.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  uncond_data = torch.load(f'{prompt_cache_dir}/uncond_{max_length}token.pth', map_location='cpu')\n",
      "/n/home12/hjkim/Github/DiffusionObjectRelation/utils/pixart_sampling_utils.py:148: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embed = torch.load(f'{prompt_cache_dir}/{prompt}_{max_length}token.pth', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 20, 4096])\n",
      "torch.Size([50, 20])\n"
     ]
    }
   ],
   "source": [
    "validation_prompts = config.validation_prompts\n",
    "prompt_cache_dir = config.prompt_cache_dir\n",
    "img_per_prompt = 25\n",
    "sequence_length = config.model_max_length\n",
    "prompt_index = 5\n",
    "image_logs_sel, latents_traj_sel, pred_traj_sel, t_traj_sel = visualize_prompts_with_traj        (pipeline, validation_prompts[prompt_index:prompt_index+1], prompt_cache_dir, config.model_max_length, weight_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['triangle is to the upper left of square',\n",
       " 'blue triangle is to the upper left of red square',\n",
       " 'triangle is above and to the right of square',\n",
       " 'blue circle is above and to the right of blue square',\n",
       " 'triangle is to the left of square',\n",
       " 'triangle is to the left of triangle',\n",
       " 'circle is below red square',\n",
       " 'red circle is to the left of blue square',\n",
       " 'blue square is to the right of red circle',\n",
       " 'red circle is above square',\n",
       " 'triangle is above red circle',\n",
       " 'red is above blue',\n",
       " 'red is to the left of red',\n",
       " 'blue triangle is above red triangle',\n",
       " 'blue circle is above blue square']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['triangle is to the left of triangle']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_prompts[prompt_index:prompt_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_logs_sel[0]['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer2DModel(\n",
       "  (pos_embed): PatchEmbed(\n",
       "    (proj): Conv2d(4, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0-11): 12 x BasicTransformerBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn1): Attention(\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn2): Attention(\n",
       "        (to_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (net): ModuleList(\n",
       "          (0): GELU(\n",
       "            (proj): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_out): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "  (proj_out): Linear(in_features=768, out_features=32, bias=True)\n",
       "  (adaln_single): AdaLayerNormSingle(\n",
       "    (emb): PixArtAlphaCombinedTimestepSizeEmbeddings(\n",
       "      (time_proj): Timesteps()\n",
       "      (timestep_embedder): TimestepEmbedding(\n",
       "        (linear_1): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (act): SiLU()\n",
       "        (linear_2): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (linear): Linear(in_features=768, out_features=4608, bias=True)\n",
       "  )\n",
       "  (caption_projection): PixArtAlphaTextProjection(\n",
       "    (linear_1): Linear(in_features=4096, out_features=768, bias=True)\n",
       "    (act_1): GELU(approximate='tanh')\n",
       "    (linear_2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PixArt model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Embedding\n",
    "\n",
    "class PatchEmbeddingScratch(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, patch_size=2):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "                              kernel_size=(patch_size, patch_size), \n",
    "                              stride=(patch_size, patch_size), padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        patch_proj = self.proj(x)\n",
    "        patch_proj = rearrange(patch_proj, \"b c h w -> b (h w) c\")\n",
    "        return patch_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_patch_embedding(model):\n",
    "    proj = PatchEmbeddingScratch(in_channels=4, out_channels=768, patch_size=2)\n",
    "    proj.load_state_dict(model.x_embedder.state_dict())\n",
    "    with torch.no_grad():\n",
    "        tmp_state = torch.randn(5, 4, 16, 16)\n",
    "        print(proj(tmp_state).shape)\n",
    "        print(model.x_embedder(tmp_state).shape)\n",
    "        assert torch.allclose(proj(tmp_state), model.x_embedder(tmp_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 768])\n",
      "torch.Size([5, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "test_patch_embedding(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Position Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position Embedding\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    half_dim = embed_dim // 2\n",
    "    omega = np.arange(half_dim, dtype=np.float64) / half_dim\n",
    "    omega = 1. / 10000 ** omega  # (D/2,)\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    args = pos[:, None] * omega[None, :]  # (M, D/2), outer product\n",
    "    return np.concatenate([np.sin(args), np.cos(args)], axis=1)\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "    return np.concatenate([emb_h, emb_w], axis=1)\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False, extra_tokens=0, lewei_scale=1.0, base_size=8):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    if isinstance(grid_size, int):\n",
    "        grid_size = (grid_size, grid_size)\n",
    "    \n",
    "    grid_h = np.arange(grid_size[0], dtype=np.float32) / (grid_size[0] / base_size) / lewei_scale # note this is basically np.arange(grid_size[0]), remove the base_size which should be the same as the grid_size. \n",
    "    grid_w = np.arange(grid_size[1], dtype=np.float32) / (grid_size[1] / base_size) / lewei_scale\n",
    "    grid = np.meshgrid(grid_w, grid_h)  # here x coordinate goes first, y coordinate goes second\n",
    "    grid = np.stack(grid, axis=0)\n",
    "    grid = grid.reshape([2, grid_size[1], grid_size[0]])\n",
    "\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token and extra_tokens > 0:\n",
    "        pos_embed = np.concatenate([np.zeros([extra_tokens, embed_dim]), pos_embed], axis=0)\n",
    "    return pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 768)\n"
     ]
    }
   ],
   "source": [
    "def test_pos_embed(model):\n",
    "    pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "    print(pos_embed.shape)\n",
    "    assert torch.allclose(torch.tensor(pos_embed).to(torch.float32), \n",
    "                        model.pos_embed[0]), \"Position embedding does not match\"\n",
    "\n",
    "test_pos_embed(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize patch position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 768])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.8415,  0.8153,  0.7886,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.9093,  0.9442,  0.9698,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         ...,\n",
      "         [-0.9589, -0.9986, -0.9856,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.2794, -0.5348, -0.7393,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.6570,  0.3792,  0.0764,  ...,  1.0000,  1.0000,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(model.pos_embed.shape)\n",
    "print(model.pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figh, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "for i in range(25):\n",
    "    axs[i].imshow(model.pos_embed.reshape(8, 8, 768).\\\n",
    "                detach().cpu().numpy()[:, :, 384+i])\n",
    "    axs[i].set_title(f\"dim {i}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.suptitle(\"Patch Position Embedding from pretrained model PixArt\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.pos_embed.reshape(8, 8, 768).\\\n",
    "            detach().cpu().numpy()[:, :, -2])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time step embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Embedding\n",
    "\n",
    "def get_sinusoidal_embedding(t, dim, max_period=10000, device=\"cpu\"):\n",
    "    half = dim // 2\n",
    "    # freqs = torch.float_power(max_period, -torch.arange(start=0, end=half, dtype=torch.float32, device=device) / half).to(torch.float32)\n",
    "    freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32, device=device) / half)\n",
    "    args = t[:, None].float() * freqs[None]\n",
    "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "    if dim % 2:\n",
    "        # in case the dimension is odd, add a zero embedding for the last dimension\n",
    "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "class TimeEmbeddingScratch(nn.Module):\n",
    "    def __init__(self, hidden_dim, freq_embedding_size=256, max_period=10000):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(freq_embedding_size, hidden_dim, bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim, bias=True),\n",
    "        )\n",
    "        self.freq_embedding_size = freq_embedding_size\n",
    "        self.max_period = max_period\n",
    "        \n",
    "    def forward(self, t):\n",
    "        sin_emb = get_sinusoidal_embedding(t, self.freq_embedding_size, self.max_period, device=t.device) #.to(self.dtype)\n",
    "        return self.mlp(sin_emb)\n",
    "    \n",
    "\n",
    "def get_time_blocks(hidden_size):\n",
    "    return nn.Sequential(\n",
    "        nn.SiLU(),\n",
    "        nn.Linear(hidden_size, hidden_size * 6, bias=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_blocks(model):\n",
    "    t_blocks = get_time_blocks(768)\n",
    "    # Test the time embedding\n",
    "    t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "    tmp_state = torch.randn(5, 768)\n",
    "    assert torch.allclose(t_blocks(tmp_state), model.t_block(tmp_state))\n",
    "    \n",
    "    \n",
    "def test_time_embedding_and_blocks(model):\n",
    "    tmp_state = torch.randint(0, 1000, (10,))\n",
    "    t_emb = TimeEmbeddingScratch(768, )\n",
    "    t_emb.load_state_dict(model.t_embedder.state_dict())\n",
    "    assert torch.allclose(t_emb(tmp_state), model.t_embedder(tmp_state)), \"Time embedding does not match\"\n",
    "    t_blocks = get_time_blocks(768)\n",
    "    t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "    assert torch.allclose(t_blocks(t_emb(tmp_state)), \n",
    "                          model.t_block(model.t_embedder(tmp_state))), \"Time blocks does not match\"\n",
    "\n",
    "\n",
    "test_time_embedding_and_blocks(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class CaptionEmbeddingScratch(nn.Module):\n",
    "    def __init__(self, in_features=4096, hidden_features=768, max_length=20):\n",
    "        super().__init__()\n",
    "        self.y_proj = nn.Sequential(OrderedDict([\n",
    "            (\"fc1\", nn.Linear(in_features, hidden_features, bias=True)),\n",
    "            (\"act\", nn.GELU(approximate='tanh')),\n",
    "            (\"drop1\", nn.Dropout(p=0)),\n",
    "            (\"fc2\", nn.Linear(hidden_features, hidden_features, bias=True)),\n",
    "            (\"drop2\", nn.Dropout(p=0))\n",
    "        ]))\n",
    "        self.y_embedding = nn.Parameter(torch.randn(max_length, in_features) / in_features ** 0.5)\n",
    "        # self.register_buffer(\"y_embedding\", nn.Parameter(torch.randn(120, in_features) / 10 ** 0.5))\n",
    "\n",
    "    # TODO: implement token dropout for classifier-free guidance\n",
    "    \n",
    "    def forward(self, x, train=False):\n",
    "        assert train == False, \"Token dropout is not implemented\"\n",
    "        return self.y_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaptionEmbedder(\n",
       "  (y_proj): Mlp(\n",
       "    (fc1): Linear(in_features=4096, out_features=768, bias=True)\n",
       "    (act): GELU(approximate='tanh')\n",
       "    (drop1): Dropout(p=0, inplace=False)\n",
       "    (norm): Identity()\n",
       "    (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (drop2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.y_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_caption_embedding(model):  \n",
    "    y_embedder = CaptionEmbeddingScratch(in_features=4096, hidden_features=768)\n",
    "    y_embedder.load_state_dict(model.y_embedder.state_dict())\n",
    "    with torch.no_grad():\n",
    "        tmp_state = torch.randn(5, 20, 4096)\n",
    "        assert torch.allclose(y_embedder(tmp_state), model.y_embedder(tmp_state, train=False))\n",
    "\n",
    "\n",
    "test_caption_embedding(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layers\n",
    "from xformers.ops import memory_efficient_attention\n",
    "import torch.nn.functional as F\n",
    "class AttentionScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_heads=12):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        self.qkv = nn.Linear(hidden_size, hidden_size * 3, bias=True)\n",
    "        self.attn_drop = nn.Dropout(0.0)\n",
    "        self.proj = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.proj_drop = nn.Dropout(0.0)\n",
    "\n",
    "    def forward(self, x, ):\n",
    "        B, N, C = x.shape\n",
    "        QKV = self.qkv(x)\n",
    "        QKV = QKV.reshape(B, N, 3, self.num_heads, self.head_dim)\n",
    "        # the F.scaled_dot_product_attention is not exactly the same as the memory_efficient_attention, but very close. \n",
    "        # Q, K, V = QKV.chunk(3, dim=-1) # (B, N, C)\n",
    "        # Q = rearrange(Q, \"b n (h d) -> (b h) n d\", h=self.num_heads)\n",
    "        # K = rearrange(K, \"b n (h d) -> (b h) n d\", h=self.num_heads)\n",
    "        # V = rearrange(V, \"b n (h d) -> (b h) n d\", h=self.num_heads)\n",
    "        # mha = F.scaled_dot_product_attention(Q, K, V, attn_mask=None, dropout_p=0.0, is_causal=False)\n",
    "        # mha = rearrange(mha, \"(b h) n d -> b n (h d)\", h=self.num_heads)\n",
    "        # Closer to the original implementation\n",
    "        Q, K, V = QKV.unbind(2)\n",
    "        mha = memory_efficient_attention(Q, K, V, p=0.0)\n",
    "        mha = mha.reshape(B, N, C)\n",
    "        return self.proj_drop(self.proj(mha))\n",
    "\n",
    "\n",
    "class CrossAttentionScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, encoder_hidden_size=768, num_heads=12, qkv_bias=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        self.cross_attn = nn.Identity()\n",
    "        self.q_linear = nn.Linear(hidden_size, hidden_size, bias=qkv_bias)\n",
    "        self.kv_linear = nn.Linear(encoder_hidden_size, hidden_size * 2, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(0.0)\n",
    "        self.proj = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.proj_drop = nn.Dropout(0.0)\n",
    "        \n",
    "    def forward(self, x, y, mask=None):\n",
    "        B, N, C = x.shape\n",
    "        # _, M, _ = y.shape\n",
    "        M = y.shape[-2]\n",
    "        Q = self.q_linear(x)\n",
    "        Q = Q.reshape(B, N, self.num_heads, self.head_dim)\n",
    "        K, V = self.kv_linear(y).reshape(B, -1, 2, self.num_heads, self.head_dim).unbind(2)\n",
    "        if mask is not None:\n",
    "            # assume mask is a boolean tensor of shape (B, 1, 1, M)\n",
    "            if mask.ndim == 2:\n",
    "                mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "            attn_bias = torch.zeros([B, self.num_heads, N, M], dtype=Q.dtype, device=Q.device)\n",
    "            attn_bias.masked_fill_(mask.repeat(1, self.num_heads, 1, 1) == 0, float('-inf'))\n",
    "            # attn_bias = torch.zeros([B * self.num_heads, q.shape[1], k.shape[1]], dtype=q.dtype, device=q.device)\n",
    "        else:\n",
    "            attn_bias = None\n",
    "        attn = memory_efficient_attention(Q, K, V, p=0.0, attn_bias=attn_bias)\n",
    "        attn = attn.reshape(B, N, C)\n",
    "        return self.proj_drop(self.proj(attn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2i_modulate(x, shift, scale):\n",
    "    return x * (1 + scale) + shift\n",
    "\n",
    "\n",
    "class TransformerBlockScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_heads=12, mlp_ratio=4.0, drop_path=0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.drop_path = drop_path\n",
    "        self.norm1 = nn.LayerNorm(768, elementwise_affine=False, eps=1e-6)\n",
    "        self.attn = AttentionScratch(hidden_size=hidden_size, num_heads=num_heads)\n",
    "        self.cross_attn = CrossAttentionScratch(hidden_size=hidden_size, encoder_hidden_size=hidden_size, num_heads=num_heads)\n",
    "        self.norm2 = nn.LayerNorm(768, elementwise_affine=False, eps=1e-6)\n",
    "        self.mlp = nn.Sequential(OrderedDict([\n",
    "            (\"fc1\", nn.Linear(hidden_size, int(hidden_size * mlp_ratio), bias=True)),\n",
    "            (\"act\", nn.GELU(approximate='tanh')),\n",
    "            (\"drop1\", nn.Dropout(p=0, inplace=False)),\n",
    "            (\"fc2\", nn.Linear(int(hidden_size * mlp_ratio), hidden_size, bias=True)),\n",
    "            (\"drop2\", nn.Dropout(p=0, inplace=False))\n",
    "        ]))\n",
    "        self.drop_path = nn.DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.scale_shift_table = nn.Parameter(torch.randn(6, hidden_size) / hidden_size ** 0.5)\n",
    "\n",
    "    def forward(self, x, y, t, mask=None, **kwargs):\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (self.scale_shift_table[None] + t.reshape(B, 6, -1)).chunk(6, dim=1)\n",
    "        x = x + self.drop_path(gate_msa * self.attn(t2i_modulate(self.norm1(x), shift_msa, scale_msa)).reshape(B, N, C))\n",
    "        x = x + self.cross_attn(x, y, mask)\n",
    "        x = x + self.drop_path(gate_mlp * self.mlp(t2i_modulate(self.norm2(x), shift_mlp, scale_mlp)))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PixArtBlock(\n",
       "  (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "  (attn): WindowAttention(\n",
       "    (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "    (q_norm): Identity()\n",
       "    (k_norm): Identity()\n",
       "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (cross_attn): MultiHeadCrossAttention(\n",
       "    (q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (kv_linear): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "  (mlp): Mlp(\n",
       "    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (act): GELU(approximate='tanh')\n",
       "    (drop1): Dropout(p=0, inplace=False)\n",
       "    (norm): Identity()\n",
       "    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (drop2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (drop_path): Identity()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `WindowAttention` is not really used, window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowAttention(\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (q_norm): Identity()\n",
       "  (k_norm): Identity()\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadCrossAttention(\n",
       "  (q_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (kv_linear): Linear(in_features=768, out_features=1536, bias=True)\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mlp(\n",
       "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (act): GELU(approximate='tanh')\n",
       "  (drop1): Dropout(p=0, inplace=False)\n",
       "  (norm): Identity()\n",
       "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (drop2): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check MLP output correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m tmp_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m768\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     14\u001b[0m mlp_out \u001b[38;5;241m=\u001b[39m mlp(tmp_state)\n\u001b[0;32m---> 15\u001b[0m mlp_out_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(mlp_out, mlp_out_model, )\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/timm/layers/mlp.py:44\u001b[0m, in \u001b[0;36mMlp.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop1(x)\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "hidden_size = 768\n",
    "mlp_ratio = 4.0\n",
    "mlp = nn.Sequential(OrderedDict([\n",
    "    (\"fc1\", nn.Linear(hidden_size, int(hidden_size * mlp_ratio), bias=True)),\n",
    "    (\"act\", nn.GELU(approximate='tanh')),\n",
    "    (\"drop1\", nn.Dropout(p=0, inplace=False)),\n",
    "    (\"fc2\", nn.Linear(int(hidden_size * mlp_ratio), hidden_size, bias=True)),\n",
    "    (\"drop2\", nn.Dropout(p=0, inplace=False))\n",
    "]))\n",
    "mlp.load_state_dict(model.blocks[-1].mlp.state_dict())\n",
    "with torch.no_grad():\n",
    "    mlp.cuda()\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    mlp_out = mlp(tmp_state)\n",
    "    mlp_out_model = model.blocks[-1].mlp(tmp_state)\n",
    "    assert torch.allclose(mlp_out, mlp_out_model, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check attention output correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass of Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowAttention(\n",
       "  (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  (q_norm): Identity()\n",
       "  (k_norm): Identity()\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[-1].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_src = AttentionScratch()\n",
    "attn_src.load_state_dict(model.blocks[-1].attn.state_dict())\n",
    "attn_src.cuda()\n",
    "with torch.no_grad():\n",
    "    model.cuda()\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    attn_output_src = attn_src(tmp_state)\n",
    "    attn_output_model = model.blocks[-1].attn(tmp_state) \n",
    "    assert torch.allclose(attn_output_src, attn_output_model, ), \"Self Attention output is not exactly the same\" # it's not exactly the same, but seems close enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attn_src = CrossAttentionScratch()\n",
    "cross_attn_src.load_state_dict(model.blocks[-1].cross_attn.state_dict())\n",
    "cross_attn_src.cuda()\n",
    "with torch.no_grad():\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    tmp_state_y = torch.randn(5, 20, 768).cuda()\n",
    "    attn_mask = None #torch.randint(0, 2, (5, 20)).cuda()\n",
    "    attn_output_src = cross_attn_src(tmp_state, tmp_state_y, mask=attn_mask)\n",
    "    attn_output_model = model.blocks[-1].cross_attn(tmp_state, tmp_state_y, mask=attn_mask) \n",
    "    assert torch.allclose(attn_output_src, attn_output_model, ), \"Cross Attention output is not exactly the same\" # it's not exactly the same, but seems close enough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = torch.zeros(5, 20).cuda().unsqueeze(1).unsqueeze(1)\n",
    "# y = y.squeeze(1).masked_select(attn_mask.unsqueeze(-1) != 0).view(1, -1, x.shape[-1])\n",
    "y_lens = attn_mask.sum(dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 2\n",
    "cross_attn_src = CrossAttentionScratch()\n",
    "cross_attn_src.load_state_dict(model.blocks[block_idx].cross_attn.state_dict())\n",
    "cross_attn_src.cuda()\n",
    "with torch.no_grad():\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    tmp_state_y = torch.randn(5, 20, 768).cuda()\n",
    "    attn_mask = torch.zeros(5, 20, dtype=torch.bool).cuda()\n",
    "    attn_mask[:, 0:1] = True\n",
    "    attn_mask[2, 0:4] = True\n",
    "    attn_mask[3, 0:3] = True\n",
    "    # attn_mask = attn_mask.unsqueeze(1).unsqueeze(1)\n",
    "    y_lens = attn_mask.squeeze(1).squeeze(1).sum(dim=1).tolist()\n",
    "    attn_output_src = cross_attn_src(tmp_state, tmp_state_y, mask=attn_mask)\n",
    "    attn_output_model = model.blocks[block_idx].cross_attn(tmp_state, tmp_state_y, mask=y_lens) \n",
    "    assert torch.allclose(attn_output_src, attn_output_model, ) # it's not exactly the same, but seems close enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 4, 3, 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xformers\n",
    "attn_bias = xformers.ops.fmha.BlockDiagonalMask.from_seqlens([64] * 5, y_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockDiagonalMask(q_seqinfo=_SeqLenInfo(seqstart=tensor([  0,  64, 128, 192, 256, 320], device='cuda:0', dtype=torch.int32), max_seqlen=64, min_seqlen=64, seqstart_py=[0, 64, 128, 192, 256, 320]), k_seqinfo=_SeqLenInfo(seqstart=tensor([ 0,  1,  2,  6,  9, 10], device='cuda:0', dtype=torch.int32), max_seqlen=4, min_seqlen=1, seqstart_py=[0, 1, 2, 6, 9, 10]), _batch_sizes=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "block_idx = 1\n",
    "block_src = TransformerBlockScratch().cuda()\n",
    "block_src.load_state_dict(model.blocks[block_idx].state_dict())\n",
    "assert torch.allclose(block_src.scale_shift_table, model.blocks[block_idx].scale_shift_table)\n",
    "with torch.no_grad():\n",
    "    block_src.eval()\n",
    "    model.eval()\n",
    "    tmp_state = torch.randn(7, 64, 768).cuda()\n",
    "    tmp_state_y = torch.randn(7, 20, 768).cuda()\n",
    "    tmp_t = torch.randn(7, 768 * 6).cuda()\n",
    "    attn_mask = torch.zeros(7, 20, dtype=torch.bool).cuda().unsqueeze(1).unsqueeze(1)\n",
    "    attn_mask[:, :, :, 0:1] = True\n",
    "    attn_mask[2, :, :, 0:4] = True\n",
    "    attn_mask[4, :, :, 0:4] = True\n",
    "    y_lens = attn_mask.squeeze(1).squeeze(1).sum(dim=1).tolist()\n",
    "    src_out = block_src(tmp_state, tmp_state_y, tmp_t, mask=attn_mask)\n",
    "    model_out = model.blocks[block_idx](tmp_state, tmp_state_y, tmp_t, mask=y_lens)\n",
    "    assert torch.allclose(src_out, model_out, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking gating parameters correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_tmp = torch.randn(7, 64, 768).cuda()\n",
    "torch.allclose(model.blocks[block_idx].attn(state_tmp), block_src.attn(state_tmp))\n",
    "# model.blocks[block_idx].attn(state_tmp)\n",
    "# block_src.attn(state_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_msa_src, scale_msa_src, gate_msa_src, shift_mlp_src, scale_mlp_src, gate_mlp_src = (block_src.scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    "shift_msa_model, scale_msa_model, gate_msa_model, shift_mlp_model, scale_mlp_model, gate_mlp_model = (model.blocks[block_idx].scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    " \n",
    "state_src = (t2i_modulate(block_src.norm1(tmp_state), shift_msa_src, scale_msa_src))\n",
    "state_model = (t2i_modulate(model.blocks[block_idx].norm1(tmp_state), shift_msa_model, scale_msa_model))\n",
    "# this is true, \n",
    "# this is not true, the attention is not the same\n",
    "# state_src = block_src.attn(t2i_modulate(block_src.norm1(tmp_state), shift_msa_src, scale_msa_src))\n",
    "# state_model = model.blocks[block_idx].attn(t2i_modulate(model.blocks[block_idx].norm1(tmp_state), shift_msa_model, scale_msa_model))\n",
    "torch.allclose(state_src, state_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_params_src = (block_src.scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    "gating_params_model = (model.blocks[block_idx].scale_shift_table[None] + tmp_t.reshape(7, 6, -1)).chunk(6, dim=1)\n",
    "assert all(torch.allclose(gating_params_src, gating_params_model) for gating_params_src, gating_params_model in zip(gating_params_src, gating_params_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 64, 768]), torch.Size([7, 64, 768]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_out.shape, model_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final readout layer \n",
    "class FinalLayerScratch(nn.Module):\n",
    "    def __init__(self, hidden_size=768, out_channel=32):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.norm_final = nn.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6)\n",
    "        self.linear = nn.Linear(hidden_size, out_channel, bias=True)\n",
    "        self.scale_shift_table = nn.Parameter(torch.randn(2, hidden_size) / hidden_size ** 0.5)\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        shift, scale = (self.scale_shift_table[None] + t_emb[:, None]).chunk(2, dim=1)\n",
    "        x = t2i_modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def unpatchify(x, patch_size=2):\n",
    "    '''\n",
    "    TODO: learn eionops notation\n",
    "    '''\n",
    "    B, T, C = x.shape\n",
    "    H = W = int(T ** 0.5)\n",
    "    assert H * W == T\n",
    "    x = rearrange(x, \"b (h w) (p1 p2 c) -> b c (h p1) (w p2)\", \n",
    "                    h=H, w=W, p1=patch_size, p2=patch_size)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T2IFinalLayer(\n",
       "  (norm_final): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "  (linear): Linear(in_features=768, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.final_layer.scale_shift_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer_src = FinalLayerScratch().cuda()\n",
    "final_layer_src.load_state_dict(model.final_layer.state_dict())\n",
    "with torch.no_grad():\n",
    "    tmp_state = torch.randn(5, 64, 768).cuda()\n",
    "    tmp_t = torch.randn(5, 768).cuda()\n",
    "    final_out_src = final_layer_src(tmp_state, tmp_t)\n",
    "    final_out_model = model.final_layer(tmp_state, tmp_t)\n",
    "    assert torch.allclose(final_out_src, final_out_model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hidden_tmp = torch.randn(5, 64, 32)\n",
    "assert torch.allclose(unpatchify(hidden_tmp), model.unpatchify(hidden_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass(model, batch_size=7, device=\"cuda\"):\n",
    "    model.eval().to(device)\n",
    "    # Define the modules from scratch\n",
    "    patch_size = 2\n",
    "    hidden_size = 768\n",
    "    num_heads = 12\n",
    "    in_channels = 4\n",
    "    out_channels = in_channels * 2\n",
    "    mlp_ratio = 4.0\n",
    "    drop_path = 0.0\n",
    "    pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "    pos_embed = torch.from_numpy(pos_embed).unsqueeze(0).to(torch.float32).to(device)\n",
    "    x_embedder = PatchEmbeddingScratch(in_channels=in_channels, out_channels=hidden_size, patch_size=patch_size)\n",
    "    t_embedder = TimeEmbeddingScratch(hidden_size, freq_embedding_size=256)\n",
    "    t_blocks = get_time_blocks(hidden_size)\n",
    "    y_embedder = CaptionEmbeddingScratch(in_features=4096, hidden_features=hidden_size)\n",
    "    final_layer = FinalLayerScratch(hidden_size=hidden_size, out_channel=out_channels * patch_size * patch_size)\n",
    "\n",
    "    x_embedder.load_state_dict(model.x_embedder.state_dict())\n",
    "    t_embedder.load_state_dict(model.t_embedder.state_dict())\n",
    "    t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "    y_embedder.load_state_dict(model.y_embedder.state_dict())\n",
    "    final_layer.load_state_dict(model.final_layer.state_dict())\n",
    "\n",
    "    transformer_blocks = nn.ModuleList([TransformerBlockScratch(hidden_size=hidden_size, num_heads=num_heads, mlp_ratio=mlp_ratio, drop_path=drop_path) for _ in range(12)])\n",
    "    transformer_blocks.load_state_dict(model.blocks.state_dict())\n",
    "    for module in [x_embedder, t_embedder, t_blocks, y_embedder, final_layer, transformer_blocks]:\n",
    "        module.eval()\n",
    "        module.requires_grad = False\n",
    "        module.to(device)\n",
    "\n",
    "    # Generate psuedo input\n",
    "    x_tmp = torch.randn(batch_size, 4, 16, 16).to(device)\n",
    "    t_tmp = torch.randint(0, 1000, (batch_size,)).to(device)\n",
    "    y_tmp = torch.randn(batch_size, 20, 4096).to(device)\n",
    "    attn_mask = torch.zeros(batch_size, 20, dtype=torch.bool).to(device)\n",
    "    attn_mask[:, 0:1] = True\n",
    "    attn_mask[2, 0:4] = True\n",
    "    attn_mask[4, 0:4] = True\n",
    "    \n",
    "    # Forward pass \n",
    "    x_embed = x_embedder(x_tmp) # (B, T, D) (Batch, num of Tokens, Embedding Dimension/Features)\n",
    "    x_embed = x_embed + pos_embed # (B, T, D)\n",
    "    t_embed = t_embedder(t_tmp) # (B, D)\n",
    "    t_blocks_out = t_blocks(t_embed) # (B, D * 6)\n",
    "    y_embed = y_embedder(y_tmp, train=False) # (B, 1, L, D) (L = length of sentence/token)\n",
    "    print(\"X input shape:\", x_tmp.shape)\n",
    "    print(\"Pos embed shape:\", pos_embed.shape)\n",
    "    print(\"T embed shape:\", t_embed.shape)\n",
    "    print(\"T blocks out shape:\", t_blocks_out.shape)\n",
    "    print(\"Y embed shape:\", y_embed.shape)\n",
    "\n",
    "    # go through the transformer blocks\n",
    "    for block in transformer_blocks:\n",
    "        x_embed = block(x_embed, y_embed, t_blocks_out, mask=attn_mask)\n",
    "\n",
    "    final_out = final_layer(x_embed, t_embed)\n",
    "    final_out = unpatchify(final_out)\n",
    "    \n",
    "    # compare with the model\n",
    "    final_out_model = model.forward(x_tmp, t_tmp, y_tmp, mask=attn_mask)\n",
    "    assert torch.allclose(final_out, final_out_model, )\n",
    "    return final_out, final_out_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "x_embedder = PatchEmbeddingScratch(in_channels=4, out_channels=768, patch_size=2)\n",
    "t_embedder = TimeEmbeddingScratch(768, freq_embedding_size=256)\n",
    "t_blocks = get_time_blocks(768)\n",
    "y_embedder = CaptionEmbeddingScratch(in_features=4096, hidden_features=768)\n",
    "final_layer = FinalLayerScratch(hidden_size=768, out_channel=32)\n",
    "\n",
    "x_embedder.load_state_dict(model.x_embedder.state_dict())\n",
    "t_embedder.load_state_dict(model.t_embedder.state_dict())\n",
    "t_blocks.load_state_dict(model.t_block.state_dict())\n",
    "y_embedder.load_state_dict(model.y_embedder.state_dict())\n",
    "final_layer.load_state_dict(model.final_layer.state_dict())\n",
    "\n",
    "transformer_blocks = nn.ModuleList([TransformerBlockScratch().cuda() for _ in range(12)])\n",
    "transformer_blocks.load_state_dict(model.blocks.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "for module in [x_embedder, t_embedder, t_blocks, y_embedder, final_layer, transformer_blocks]:\n",
    "    module.eval()\n",
    "    module.requires_grad = False\n",
    "    module.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X input shape: torch.Size([5, 4, 16, 16])\n",
      "Pos embed shape: torch.Size([1, 64, 768])\n",
      "T embed shape: torch.Size([5, 768])\n",
      "T blocks out shape: torch.Size([5, 4608])\n",
      "Y embed shape: torch.Size([5, 20, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8, 16, 16])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass \n",
    "x_tmp = torch.randn(5, 4, 16, 16).to(device)\n",
    "t_tmp = torch.randint(0, 1000, (5,)).to(device)\n",
    "y_tmp = torch.randn(5, 20, 4096).to(device)\n",
    "pos_embed = get_2d_sincos_pos_embed(768, (8, 8))\n",
    "pos_embed = torch.tensor(pos_embed).unsqueeze(0).to(torch.float32).to(device)\n",
    "attn_mask = torch.zeros(5, 20, dtype=torch.bool).to(device)\n",
    "attn_mask[:, 0:1] = True\n",
    "attn_mask[2, 0:4] = True\n",
    "attn_mask[4, 0:4] = True\n",
    "\n",
    "x_embed = x_embedder(x_tmp) # (B, T, D)\n",
    "x_embed = x_embed + pos_embed # (B, T, D)\n",
    "t_embed = t_embedder(t_tmp) # (B, D)\n",
    "t_blocks_out = t_blocks(t_embed) # (B, D * 6)\n",
    "y_embed = y_embedder(y_tmp, train=False) # (B, 1, L, D)\n",
    "print(\"X input shape:\", x_tmp.shape)\n",
    "print(\"Pos embed shape:\", pos_embed.shape)\n",
    "print(\"T embed shape:\", t_embed.shape)\n",
    "print(\"T blocks out shape:\", t_blocks_out.shape)\n",
    "print(\"Y embed shape:\", y_embed.shape)\n",
    "\n",
    "# go through the transformer blocks\n",
    "for block in transformer_blocks:\n",
    "    x_embed = block(x_embed, y_embed, t_blocks_out, mask=attn_mask)\n",
    "\n",
    "final_out = final_layer(x_embed, t_embed)\n",
    "final_out = unpatchify(final_out)\n",
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/hjkim/.conda/envs/torch2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "final_out_model = model.forward(x_tmp, t_tmp, y_tmp, mask=attn_mask)\n",
    "assert torch.allclose(final_out, final_out_model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
