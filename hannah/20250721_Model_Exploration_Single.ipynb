{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the single object datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/hjkim/.conda/envs/torch2/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/n/home12/hjkim/.conda/envs/torch2/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/n/home12/hjkim/.conda/envs/torch2/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "from diffusers import AutoencoderKL, Transformer2DModel, PixArtAlphaPipeline, DPMSolverMultistepScheduler\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/hjkim/Github/DiffusionObjectRelation/PixArt-alpha\")\n",
    "\n",
    "from diffusion import IDDPM\n",
    "from diffusion.data.builder import build_dataset, build_dataloader, set_data_root\n",
    "from diffusion.model.builder import build_model\n",
    "from diffusion.utils.misc import set_random_seed, read_config, init_random_seed, DebugUnderflowOverflow\n",
    "sys.path.append(\"/n/home12/hjkim/Github/DiffusionObjectRelation/utils\")\n",
    "from pixart_utils import state_dict_convert\n",
    "from image_utils import pil_images_to_grid\n",
    "from pixart_utils import state_dict_convert\n",
    "from pixart_sampling_utils import PixArtAlphaPipeline_custom, visualize_prompts_with_traj\n",
    "from pixart_utils import construct_diffuser_transformer_from_config, construct_diffuser_pipeline_from_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/DL_Projects/PixArt/results/objrel_rndembdposemb_DiT_B_pilot\"\n",
    "\n",
    "\n",
    "config = read_config(join(savedir, 'config.py'))\n",
    "\n",
    "weight_dtype = torch.float32\n",
    "if config.mixed_precision == \"fp16\": # accelerator.\n",
    "    weight_dtype = torch.float16\n",
    "elif config.mixed_precision == \"bf16\": # accelerator.\n",
    "    weight_dtype = torch.bfloat16\n",
    "    \n",
    "image_size = config.image_size  # @param [256, 512, 1024]\n",
    "latent_size = int(image_size) // 8\n",
    "pred_sigma = getattr(config, 'pred_sigma', True)\n",
    "learn_sigma = getattr(config, 'learn_sigma', True) and pred_sigma\n",
    "model_kwargs={\"window_block_indexes\": config.window_block_indexes, \"window_size\": config.window_size,\n",
    "                \"use_rel_pos\": config.use_rel_pos, \"lewei_scale\": config.lewei_scale, 'config':config,\n",
    "                'model_max_length': config.model_max_length}\n",
    "# train_diffusion = IDDPM(str(config.train_sampling_steps), learn_sigma=learn_sigma, pred_sigma=pred_sigma, snr=config.snr_loss)\n",
    "model = build_model(config.model,\n",
    "                config.grad_checkpointing,\n",
    "                config.get('fp32_attention', False),\n",
    "                input_size=latent_size,\n",
    "                learn_sigma=learn_sigma,\n",
    "                pred_sigma=pred_sigma,\n",
    "                **model_kwargs).train()\n",
    "\n",
    "transformer = Transformer2DModel(\n",
    "        sample_size=image_size // 8,\n",
    "        num_layers=len(model.blocks),\n",
    "        attention_head_dim=model.blocks[0].hidden_size // model.num_heads,\n",
    "        in_channels=model.in_channels,\n",
    "        out_channels=model.out_channels,\n",
    "        patch_size=model.patch_size,\n",
    "        attention_bias=True,\n",
    "        num_attention_heads=model.num_heads,\n",
    "        cross_attention_dim=model.blocks[0].hidden_size,\n",
    "        activation_fn=\"gelu-approximate\",\n",
    "        num_embeds_ada_norm=1000,\n",
    "        norm_type=\"ada_norm_single\",\n",
    "        norm_elementwise_affine=False,\n",
    "        norm_eps=1e-6,\n",
    "        caption_channels=4096,\n",
    ")\n",
    "# state_dict = state_dict_convert(all_state_dict.pop(\"state_dict\"))\n",
    "transformer.load_state_dict(state_dict_convert(model.state_dict()))\n",
    "pipeline = PixArtAlphaPipeline_custom.from_pretrained(\n",
    "    \"PixArt-alpha/PixArt-XL-2-512x512\",\n",
    "    transformer=transformer,\n",
    "    tokenizer=None,\n",
    "    text_encoder=None,\n",
    "    torch_dtype=weight_dtype,\n",
    ")\n",
    "ckptdir = join(savedir, \"checkpoints\")\n",
    "ckpt = torch.load(join(ckptdir, \"epoch_4000_step_160000.pth\"))\n",
    "pipeline.transformer.load_state_dict(state_dict_convert(ckpt['state_dict_ema'])) # model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
